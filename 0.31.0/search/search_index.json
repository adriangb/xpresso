{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Xpresso is an ASGI web framework built on top of Starlette , Pydantic and di , with heavy inspiration from FastAPI . Some of the standout features are: ASGI support for high performance (within the context of Python web frameworks) OpenAPI documentation generation Automatic parsing and validation of request bodies and parameters, with hooks for custom extractors Full support for OpenAPI parameter serialization Highly typed and tested codebase with great IDE support A powerful dependency injection system, backed by di Requirements Python 3.7+ Installation pip install xpresso You'll also want to install an ASGI server, such as Uvicorn . pip install uvicorn Example Create a file named example.py : from pydantic import BaseModel from xpresso import App , Path , FromPath , FromQuery class Item ( BaseModel ): item_id : int name : str async def read_item ( item_id : FromPath [ int ], name : FromQuery [ str ]) -> Item : return Item ( item_id = item_id , name = name ) app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = read_item , ) ] ) Run the application: uvicorn example:app Navigate to http://127.0.0.1:8000/items/123?name=foobarbaz in your browser. You will get the following JSON response: { \"item_id\" : 123 , \"name\" : \"foobarbaz\" } Now navigate to http://127.0.0.1:8000/docs to poke around the interactive Swagger UI documentation: For more examples, tutorials and reference materials, see our documentation . Inspiration and relationship to other frameworks Xpresso is mainly inspired by FastAPI. FastAPI pioneered several ideas that are core to Xpresso's approach: Leverage Pydantic for JSON parsing, validation and schema generation. Leverage Starlette for routing and other low level web framework functionality. Provide a simple but powerful dependency injection system. Use that dependency injection system to provide extraction of request bodies, forms, query parameters, etc. Xpresso takes these ideas and refines them by: Decoupling the dependency injection system from the request/response cycle, leading to an overall much more flexible and powerful dependency injection system, packaged up as the standalone di library. Decoupling the framework from Pydantic by using Annotated ( PEP 593 ) instead of default values ( param: FromQuery[str] instead of param: str = Query(...) ). Middleware on Routers so that you can use generic ASGI middleware in a routing-aware manner (for example, installing profiling middleware on only some paths without using regex matching). Support for lifespans on any Router or mounted App (this silently fails in FastAPI and Starlette) dependency injection into the application lifespan and support for multiple dependency scopes . Formalizing the framework for extracting parameters and bodies from requests into the Binder API so that 3rd party extensions can do anything the framework does. Support for customizing parameter and form serialization . Better performance by implementing dependency resolution in Rust , executing dependencies concurrently and controlling threading of sync dependencies on a per-dependency basis . Current state This project is under active development. It should not be considered \"stable\" or ready to be used in production. It is however ready for experimentation and learning! What is implemented and mostly stable? Extraction and OpenAPI documentation of parameters (query, headers, etc.) and request bodies (including multipart requests). Parameter serialization. Routing, including applications, routers and routes. Dependency injection and testing utilities (dependency overrides). Most of this APIs will be generally stable going forward, although some minor aspects like argument names will probably change at some point. What is not implemented or unstable? Low-level API for binders (stuff in xpresso.binders ): this is public, but should be considered experimental and is likely to change. The high level APIs ( FromPath[str] and Annotated[str, PathParam(...)] ) are likely to be stable. Security dependencies and OpenAPI integration. This part used to exist, but needed some work. It is planned for the future, but we need to think about the scope of these features and the API.","title":"Xpresso"},{"location":"#requirements","text":"Python 3.7+","title":"Requirements"},{"location":"#installation","text":"pip install xpresso You'll also want to install an ASGI server, such as Uvicorn . pip install uvicorn","title":"Installation"},{"location":"#example","text":"Create a file named example.py : from pydantic import BaseModel from xpresso import App , Path , FromPath , FromQuery class Item ( BaseModel ): item_id : int name : str async def read_item ( item_id : FromPath [ int ], name : FromQuery [ str ]) -> Item : return Item ( item_id = item_id , name = name ) app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = read_item , ) ] ) Run the application: uvicorn example:app Navigate to http://127.0.0.1:8000/items/123?name=foobarbaz in your browser. You will get the following JSON response: { \"item_id\" : 123 , \"name\" : \"foobarbaz\" } Now navigate to http://127.0.0.1:8000/docs to poke around the interactive Swagger UI documentation: For more examples, tutorials and reference materials, see our documentation .","title":"Example"},{"location":"#inspiration-and-relationship-to-other-frameworks","text":"Xpresso is mainly inspired by FastAPI. FastAPI pioneered several ideas that are core to Xpresso's approach: Leverage Pydantic for JSON parsing, validation and schema generation. Leverage Starlette for routing and other low level web framework functionality. Provide a simple but powerful dependency injection system. Use that dependency injection system to provide extraction of request bodies, forms, query parameters, etc. Xpresso takes these ideas and refines them by: Decoupling the dependency injection system from the request/response cycle, leading to an overall much more flexible and powerful dependency injection system, packaged up as the standalone di library. Decoupling the framework from Pydantic by using Annotated ( PEP 593 ) instead of default values ( param: FromQuery[str] instead of param: str = Query(...) ). Middleware on Routers so that you can use generic ASGI middleware in a routing-aware manner (for example, installing profiling middleware on only some paths without using regex matching). Support for lifespans on any Router or mounted App (this silently fails in FastAPI and Starlette) dependency injection into the application lifespan and support for multiple dependency scopes . Formalizing the framework for extracting parameters and bodies from requests into the Binder API so that 3rd party extensions can do anything the framework does. Support for customizing parameter and form serialization . Better performance by implementing dependency resolution in Rust , executing dependencies concurrently and controlling threading of sync dependencies on a per-dependency basis .","title":"Inspiration and relationship to other frameworks"},{"location":"#current-state","text":"This project is under active development. It should not be considered \"stable\" or ready to be used in production. It is however ready for experimentation and learning!","title":"Current state"},{"location":"#what-is-implemented-and-mostly-stable","text":"Extraction and OpenAPI documentation of parameters (query, headers, etc.) and request bodies (including multipart requests). Parameter serialization. Routing, including applications, routers and routes. Dependency injection and testing utilities (dependency overrides). Most of this APIs will be generally stable going forward, although some minor aspects like argument names will probably change at some point.","title":"What is implemented and mostly stable?"},{"location":"#what-is-not-implemented-or-unstable","text":"Low-level API for binders (stuff in xpresso.binders ): this is public, but should be considered experimental and is likely to change. The high level APIs ( FromPath[str] and Annotated[str, PathParam(...)] ) are likely to be stable. Security dependencies and OpenAPI integration. This part used to exist, but needed some work. It is planned for the future, but we need to think about the scope of these features and the API.","title":"What is not implemented or unstable?"},{"location":"contributing/","text":"Contributing to Xpresso Xpresso is a pure python package that you should be able to get up in running in < 5 minutes. Clone the repo First, clone the repository: git clone https://github.com/adriangb/xpresso.git Then change directories into the repository you just cloned: cd xpresso Set up the project Automated setup If you have Make installed, you can just run: make init && make test && make lint Which will set up a virtual enviromnet (using Poetry ), install all of the project's dependencies, install git hooks and run all of the tests. Manual setup Alternatively, you can set up the project manually like any other Poetry project: pip install -U poetry poetry install Then to run tests: poetry run python -m pytest -v To install git hooks (managed by pre-commit ): pip install -U pre-commit pre-commit install And to run linters: pre-commit run --all-files Making changes First you will need to fork the repository on GitHub. Once you have your own fork, clone it and follow the instructions above to set up the project. You will make changes in your fork and then open a pull request (PR) against https://github.com/adriangb/xpresso . All changes are expected to come with tests. If the change impacts user facing behavior, it should also have documentation associated with it. Once you've made your changes and have passing tests, you can submit a PR. Every pull request merge will trigger a release, so you need to include a version bump (by editing the version in pyproject.toml ). We adhere to Semantic Versioning . Use your best judgment as to what sort of version bump your changes warrant and it will be discussed as part of the PR review process. Pull requests are squash merged, so you do not need to keep a tidy commit history, although it is appreciated if you still do keep your work in progress commit messages clear and consice to aid in the review process. You are encouraged, but not required, to use Conventional Commits .","title":"Contributing"},{"location":"contributing/#contributing-to-xpresso","text":"Xpresso is a pure python package that you should be able to get up in running in < 5 minutes.","title":"Contributing to Xpresso"},{"location":"contributing/#clone-the-repo","text":"First, clone the repository: git clone https://github.com/adriangb/xpresso.git Then change directories into the repository you just cloned: cd xpresso","title":"Clone the repo"},{"location":"contributing/#set-up-the-project","text":"","title":"Set up the project"},{"location":"contributing/#automated-setup","text":"If you have Make installed, you can just run: make init && make test && make lint Which will set up a virtual enviromnet (using Poetry ), install all of the project's dependencies, install git hooks and run all of the tests.","title":"Automated setup"},{"location":"contributing/#manual-setup","text":"Alternatively, you can set up the project manually like any other Poetry project: pip install -U poetry poetry install Then to run tests: poetry run python -m pytest -v To install git hooks (managed by pre-commit ): pip install -U pre-commit pre-commit install And to run linters: pre-commit run --all-files","title":"Manual setup"},{"location":"contributing/#making-changes","text":"First you will need to fork the repository on GitHub. Once you have your own fork, clone it and follow the instructions above to set up the project. You will make changes in your fork and then open a pull request (PR) against https://github.com/adriangb/xpresso . All changes are expected to come with tests. If the change impacts user facing behavior, it should also have documentation associated with it. Once you've made your changes and have passing tests, you can submit a PR. Every pull request merge will trigger a release, so you need to include a version bump (by editing the version in pyproject.toml ). We adhere to Semantic Versioning . Use your best judgment as to what sort of version bump your changes warrant and it will be discussed as part of the PR review process. Pull requests are squash merged, so you do not need to keep a tidy commit history, although it is appreciated if you still do keep your work in progress commit messages clear and consice to aid in the review process. You are encouraged, but not required, to use Conventional Commits .","title":"Making changes"},{"location":"types/","text":"Typing in Python This documentation assumes that you are familiar with type annotations in Python. If you are not, that is okay! There are a lot of excellent guides out there to get you started: RealPython's Python Type Checking guide FastAPI's introduction to python types Runtime types (reflection) Most languages lose a lot of their type information at runtime. This can range between complete loss of type information (like TypeScript) or only weak support for runtime reflection (Golang). Python stands out for it's strong support for typing information at runtime (often called reflection ). Because of Python's dynamic runtime behavior, it is possible to read types and modify the runtime behavior of the program. Annotated and parameter metadata Python 3.9 (via PEP 593 ) introduced the Annotated typing construct. Since it's release in Python 3.9, this construct has been backported to older Python versions via the typing_extensions package. So it is available all the way back to Python 3.7. Xpresso uses Annotated extensively since it provides a composable, cohesive and widely supported pattern for attaching metadata for function parameters and class field declarations that is available at runtime. If you've used FastAPI, you may be used to declaring things like param: str = Header() . When FastAPI was first released, this was the only way to add runtime metadata to a parameter in Python. But now there is a better way to do this! In Xpresso this same declaration would look like param: FromHeader[str] or param: Annotated[str, HeaderParam()] (the former is just syntactic sugar for the latter). As you see more usages of Annotated you will get used to it. But for now all you need to know is that param: Annotated[str, HeaderParam()] is pretty much equivalent to param: str = Header() in FastAPI. One of the main advantages to using Annotated is composability: multiple tools/libraries can include metadata together without conflict. For example, we can included information for both Xpresso and Pydantic using param: Annotated[str, Path(), Field(min_length=1) . This is in contrast to FastAPI where Query() and friends are actually subclasses of Pydantic's Field() , which couples the web framework to Pydantic and adds complexity into Query() , Path() , etc. that is not really related to them directly. To see an example of this in action, head over to the Path Parameters section of our documentation.","title":"Python Types"},{"location":"types/#typing-in-python","text":"This documentation assumes that you are familiar with type annotations in Python. If you are not, that is okay! There are a lot of excellent guides out there to get you started: RealPython's Python Type Checking guide FastAPI's introduction to python types","title":"Typing in Python"},{"location":"types/#runtime-types-reflection","text":"Most languages lose a lot of their type information at runtime. This can range between complete loss of type information (like TypeScript) or only weak support for runtime reflection (Golang). Python stands out for it's strong support for typing information at runtime (often called reflection ). Because of Python's dynamic runtime behavior, it is possible to read types and modify the runtime behavior of the program.","title":"Runtime types (reflection)"},{"location":"types/#annotated-and-parameter-metadata","text":"Python 3.9 (via PEP 593 ) introduced the Annotated typing construct. Since it's release in Python 3.9, this construct has been backported to older Python versions via the typing_extensions package. So it is available all the way back to Python 3.7. Xpresso uses Annotated extensively since it provides a composable, cohesive and widely supported pattern for attaching metadata for function parameters and class field declarations that is available at runtime. If you've used FastAPI, you may be used to declaring things like param: str = Header() . When FastAPI was first released, this was the only way to add runtime metadata to a parameter in Python. But now there is a better way to do this! In Xpresso this same declaration would look like param: FromHeader[str] or param: Annotated[str, HeaderParam()] (the former is just syntactic sugar for the latter). As you see more usages of Annotated you will get used to it. But for now all you need to know is that param: Annotated[str, HeaderParam()] is pretty much equivalent to param: str = Header() in FastAPI. One of the main advantages to using Annotated is composability: multiple tools/libraries can include metadata together without conflict. For example, we can included information for both Xpresso and Pydantic using param: Annotated[str, Path(), Field(min_length=1) . This is in contrast to FastAPI where Query() and friends are actually subclasses of Pydantic's Field() , which couples the web framework to Pydantic and adds complexity into Query() , Path() , etc. that is not really related to them directly. To see an example of this in action, head over to the Path Parameters section of our documentation.","title":"Annotated and parameter metadata"},{"location":"advanced/binders/","text":"Binders One of the core principles of Xpresso is that the framework does not get any special treatment. While it is not always possible (or worth it) to make everything customizable, by ensuring that we do not special case our own implementations we allow you, the developer, to have the ability to implement things that would otherwise have to be feature requests. This way everyone wins: we have less features to mantain, less edge cases to test and you get to make Xpresso work for your use case. Binders are a great example of this philosophy. They are how Xpresso interally processes request bodies, forms and parameters (cookies, headers, etc.). It is also how most of the OpenAPI documentation is generated. In fact, all of FromQuery / QueryParam(...) , FromMultipart / Multipart(...) and others are just a particular implementation of a Binder. In this tutorial we will dive in depth into Binders, and by the end of it we will have built a custom binder that parses MessagePack requests bodies into a Pydantic model. Note Binders are inspired by BlackSheep and ASP.NET Core . Integration into the dependency injection system is inspired by FastAPI . Experimental APIs The APIs for Binders are considered experimental. We encourage exploration and experimentation, but can't promise long term stability. Architecture First, a word on how Binders work. Binders leverage the dependency injection system. They are themselves dependencies that your endpoint function (or other dependencies) will depend on. And then they themselves depend on the incoming Request object in the case of body extractors or HTTPConnection in the case of parameters. Binders also have a dual purpose: They extract data ( Extractor ) They generate OpenAPI specs ( OpenAPIProvider s) Each one of these two functionalities has it's own protocol/interface that Binders must implement. Markers Because the same binder object can be used with multiple parameters (think about how FromJson is an alias for Annotated[..., Json()] ; the Json() object will be the same in everywhere FromJson is used) it cannot be modified in-place to record information from the parameter it is being bound to (think for example how FromQuery automatically gets the query parameter name from the the Python parameter name and the type to parse into from the type annotation). To get around this issue, we have the concept of Markers . Markers are usually just data containers that when bound to a Python parameter (an inspect.Parameter instance in fact) will produce a unique Extractor and OpenAPIProvider instance. Since we already had two interfaces to implement (Extractor and OpenAPIProvider) and each one needs a Marker, typically we will be implementing 4 different protocols/interfaces for each Binder : OpenAPI{Body,Parameter}Marker OpenAPI{Body,Parameter} {Body,Parameter}ExtractorMarker {Body,Parameter}Extractor Tip This is already a lot of information. Before trying to implement your own marker, you may want to look at the source code for FromJson to see how a Binder you are already familiar with is implemented. Custom Binders: MessagePack body In this tutorial we will be implementing a custom binder that extracts MessagePack request bodies into Pydantic models. Start by making a folder to organize your work and adding an __init__.py file. We will be putting several Python files in this folder. Tests Like any good TDD'er, we'll write some tests first. This will also help you, the reader, understand what the expected outcome is. First, we need to define an app. Create a file called tests.py with the following contents: from typing import Any , Dict import msgpack # type: ignore[import] from pydantic import BaseModel from xpresso import App , Path from xpresso.testclient import TestClient from .functions import FromMsgPack class Item ( BaseModel ): foo : str bar : int async def echo_item ( item : FromMsgPack [ Item ]) -> Item : return item app = App ( routes = [ Path ( \"/echo-item\" , put = echo_item , ) ] ) client = TestClient ( app ) def test_echo_item () -> None : payload = { \"foo\" : \"abc\" , \"bar\" : 123 } data : bytes = msgpack . packb ( payload ) # type: ignore[assignment] resp = client . put ( \"/echo-item\" , data = data ) assert resp . status_code == 200 , resp . content assert resp . json () == payload def test_openapi_schema () -> None : expected_openapi : Dict [ str , Any ] = { \"openapi\" : \"3.0.3\" , \"info\" : { \"title\" : \"API\" , \"version\" : \"0.1.0\" }, \"paths\" : { \"/echo-item\" : { \"put\" : { \"responses\" : { \"200\" : { \"description\" : \"OK\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Item\" } } }, }, \"422\" : { \"description\" : \"Validation Error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/HTTPValidationError\" } } }, }, }, \"requestBody\" : { \"content\" : { \"application/x-msgpack\" : { \"schema\" : { \"type\" : \"string\" , \"format\" : \"binary\" , } } } }, } } }, \"components\" : { \"schemas\" : { \"Item\" : { \"title\" : \"Item\" , \"required\" : [ \"foo\" , \"bar\" ], \"type\" : \"object\" , \"properties\" : { \"foo\" : { \"title\" : \"Foo\" , \"type\" : \"string\" }, \"bar\" : { \"title\" : \"Bar\" , \"type\" : \"integer\" }, }, }, \"ValidationError\" : { \"title\" : \"ValidationError\" , \"required\" : [ \"loc\" , \"msg\" , \"type\" ], \"type\" : \"object\" , \"properties\" : { \"loc\" : { \"title\" : \"Location\" , \"type\" : \"array\" , \"items\" : { \"oneOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"integer\" }, ] }, }, \"msg\" : { \"title\" : \"Message\" , \"type\" : \"string\" }, \"type\" : { \"title\" : \"Error Type\" , \"type\" : \"string\" , }, }, }, \"HTTPValidationError\" : { \"title\" : \"HTTPValidationError\" , \"type\" : \"object\" , \"properties\" : { \"detail\" : { \"title\" : \"Detail\" , \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/ValidationError\" }, } }, }, } }, } resp = client . get ( \"/openapi.json\" ) assert resp . status_code == 200 , resp . content assert resp . json () == expected_openapi if __name__ == \"__main__\" : test_echo_item () test_openapi_schema () At this point we would have just stubbed out the actual implementations (just FromMsgPack for now, something like FromMsgPack = Annotated[T, \"placeholder\"] would do). So go ahead and create a file called functions.py and add a stub for FromMsgPack . But if we run our tests ( pytest tests.py ) they fail. So we need to actually cook up the implementations next. Extractor We'll start with the extractors. Make a file called extractor.py with the following contents: import inspect import sys from typing import Any , NamedTuple , Type if sys . version_info < ( 3 , 8 ): from typing_extensions import get_args else : from typing import get_args import msgpack # type: ignore[import] from pydantic import BaseModel from xpresso import Request from xpresso.binders.api import SupportsBodyExtractor from xpresso.requests import HTTPConnection class MsgPackBodyExtractor ( NamedTuple ): model : Type [ BaseModel ] async def extract ( self , connection : HTTPConnection ) -> Any : assert isinstance ( connection , Request ) data = await connection . body () deserialized_obj : Any = msgpack . unpackb ( data ) # type: ignore[assignment] # You probably want more checks and validation here # For example, handling empty bodies # This is just a tutorial! return self . model . parse_obj ( deserialized_obj ) class MsgPackBodyExtractorMarker : def register_parameter ( self , param : inspect . Parameter ) -> SupportsBodyExtractor : # get the first paramater to Annotated, which should be our actual type model = next ( iter ( get_args ( param . annotation ))) if not issubclass ( model , BaseModel ): # You may want more rigourous checks here # Or you may want to accept non-Pydantic models # We do the easiest thing here raise TypeError ( \"MessagePack model must be a Pydantic model\" ) return MsgPackBodyExtractor ( model ) Tip All of these base classes are typing.Protocol classes. This means you do not actually have to inherit from them directly to implement them. But it can be helpful to do so to get IDE autocompletion on method signatures as you implement them. OpenAPIProvider This OpenAPIProvider will be somewhat anemic: there isn't much we can describe about MessagePack to OpenAPI other than the expected media type and that it will be binary data. Make a file called openapi.py with the following contents: import inspect import typing from xpresso.binders.api import ( ModelNameMap , Schemas , SupportsOpenAPIBody , ) from xpresso.openapi import models class OpenAPIBodyMsgPack : include_in_schema : bool = True media_type = \"application/x-msgpack\" def get_models ( self ) -> typing . List [ type ]: return [] def get_openapi_media_type ( self , model_name_map : ModelNameMap , schemas : Schemas ) -> models . MediaType : return models . MediaType ( schema = self . get_field_schema ( model_name_map , schemas ) ) def get_field_schema ( self , model_name_map : ModelNameMap , schemas : Schemas ) -> models . Schema : return models . Schema ( type = \"string\" , format = \"binary\" , ) def get_openapi_body ( self , model_name_map : ModelNameMap , schemas : Schemas ) -> models . RequestBody : return models . RequestBody ( content = { self . media_type : self . get_openapi_media_type ( model_name_map , schemas ) } ) def get_field_encoding ( self , model_name_map : ModelNameMap , schemas : Schemas ) -> models . Encoding : return models . Encoding ( contentType = self . media_type ) class OpenAPIBodyMarkerMsgPack : def register_parameter ( self , param : inspect . Parameter ) -> SupportsOpenAPIBody : return OpenAPIBodyMsgPack () You may notice that there are several pointless methods here that could have all been stuck into get_openapi() . These aren't strictly necessary here, but would be used if we tried to use this Binder as form field in a multipart/form-data request, so we are showing them to you just in case. Putting it all together Now we just need some sugar so we can call a single function and have it wire all of this stuff up. Open functions.py , remove your FromMsgPack stub and add: from typing import Any , TypeVar from xpresso.binders.dependants import BodyBinderMarker from xpresso.typing import Annotated from .extractor import MsgPackBodyExtractorMarker from .openapi import OpenAPIBodyMarkerMsgPack T = TypeVar ( \"T\" ) def MsgPack () -> Any : return BodyBinderMarker ( extractor_marker = MsgPackBodyExtractorMarker (), field_extractor_marker = None , openapi_marker = OpenAPIBodyMarkerMsgPack (), openapi_field_marker = None , ) FromMsgPack = Annotated [ T , MsgPack ()] You don't have to worry much about BodyBinderMarker . It's just a helper class that takes care of the interaction with the dependency injection system. Run the tests That's it! Now you can run the tests ( pytest tests.py ) and they should pass!","title":"Binders"},{"location":"advanced/binders/#binders","text":"One of the core principles of Xpresso is that the framework does not get any special treatment. While it is not always possible (or worth it) to make everything customizable, by ensuring that we do not special case our own implementations we allow you, the developer, to have the ability to implement things that would otherwise have to be feature requests. This way everyone wins: we have less features to mantain, less edge cases to test and you get to make Xpresso work for your use case. Binders are a great example of this philosophy. They are how Xpresso interally processes request bodies, forms and parameters (cookies, headers, etc.). It is also how most of the OpenAPI documentation is generated. In fact, all of FromQuery / QueryParam(...) , FromMultipart / Multipart(...) and others are just a particular implementation of a Binder. In this tutorial we will dive in depth into Binders, and by the end of it we will have built a custom binder that parses MessagePack requests bodies into a Pydantic model. Note Binders are inspired by BlackSheep and ASP.NET Core . Integration into the dependency injection system is inspired by FastAPI . Experimental APIs The APIs for Binders are considered experimental. We encourage exploration and experimentation, but can't promise long term stability.","title":"Binders"},{"location":"advanced/binders/#architecture","text":"First, a word on how Binders work. Binders leverage the dependency injection system. They are themselves dependencies that your endpoint function (or other dependencies) will depend on. And then they themselves depend on the incoming Request object in the case of body extractors or HTTPConnection in the case of parameters. Binders also have a dual purpose: They extract data ( Extractor ) They generate OpenAPI specs ( OpenAPIProvider s) Each one of these two functionalities has it's own protocol/interface that Binders must implement.","title":"Architecture"},{"location":"advanced/binders/#markers","text":"Because the same binder object can be used with multiple parameters (think about how FromJson is an alias for Annotated[..., Json()] ; the Json() object will be the same in everywhere FromJson is used) it cannot be modified in-place to record information from the parameter it is being bound to (think for example how FromQuery automatically gets the query parameter name from the the Python parameter name and the type to parse into from the type annotation). To get around this issue, we have the concept of Markers . Markers are usually just data containers that when bound to a Python parameter (an inspect.Parameter instance in fact) will produce a unique Extractor and OpenAPIProvider instance. Since we already had two interfaces to implement (Extractor and OpenAPIProvider) and each one needs a Marker, typically we will be implementing 4 different protocols/interfaces for each Binder : OpenAPI{Body,Parameter}Marker OpenAPI{Body,Parameter} {Body,Parameter}ExtractorMarker {Body,Parameter}Extractor Tip This is already a lot of information. Before trying to implement your own marker, you may want to look at the source code for FromJson to see how a Binder you are already familiar with is implemented.","title":"Markers"},{"location":"advanced/binders/#custom-binders-messagepack-body","text":"In this tutorial we will be implementing a custom binder that extracts MessagePack request bodies into Pydantic models. Start by making a folder to organize your work and adding an __init__.py file. We will be putting several Python files in this folder.","title":"Custom Binders: MessagePack body"},{"location":"advanced/binders/#tests","text":"Like any good TDD'er, we'll write some tests first. This will also help you, the reader, understand what the expected outcome is. First, we need to define an app. Create a file called tests.py with the following contents: from typing import Any , Dict import msgpack # type: ignore[import] from pydantic import BaseModel from xpresso import App , Path from xpresso.testclient import TestClient from .functions import FromMsgPack class Item ( BaseModel ): foo : str bar : int async def echo_item ( item : FromMsgPack [ Item ]) -> Item : return item app = App ( routes = [ Path ( \"/echo-item\" , put = echo_item , ) ] ) client = TestClient ( app ) def test_echo_item () -> None : payload = { \"foo\" : \"abc\" , \"bar\" : 123 } data : bytes = msgpack . packb ( payload ) # type: ignore[assignment] resp = client . put ( \"/echo-item\" , data = data ) assert resp . status_code == 200 , resp . content assert resp . json () == payload def test_openapi_schema () -> None : expected_openapi : Dict [ str , Any ] = { \"openapi\" : \"3.0.3\" , \"info\" : { \"title\" : \"API\" , \"version\" : \"0.1.0\" }, \"paths\" : { \"/echo-item\" : { \"put\" : { \"responses\" : { \"200\" : { \"description\" : \"OK\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Item\" } } }, }, \"422\" : { \"description\" : \"Validation Error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/HTTPValidationError\" } } }, }, }, \"requestBody\" : { \"content\" : { \"application/x-msgpack\" : { \"schema\" : { \"type\" : \"string\" , \"format\" : \"binary\" , } } } }, } } }, \"components\" : { \"schemas\" : { \"Item\" : { \"title\" : \"Item\" , \"required\" : [ \"foo\" , \"bar\" ], \"type\" : \"object\" , \"properties\" : { \"foo\" : { \"title\" : \"Foo\" , \"type\" : \"string\" }, \"bar\" : { \"title\" : \"Bar\" , \"type\" : \"integer\" }, }, }, \"ValidationError\" : { \"title\" : \"ValidationError\" , \"required\" : [ \"loc\" , \"msg\" , \"type\" ], \"type\" : \"object\" , \"properties\" : { \"loc\" : { \"title\" : \"Location\" , \"type\" : \"array\" , \"items\" : { \"oneOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"integer\" }, ] }, }, \"msg\" : { \"title\" : \"Message\" , \"type\" : \"string\" }, \"type\" : { \"title\" : \"Error Type\" , \"type\" : \"string\" , }, }, }, \"HTTPValidationError\" : { \"title\" : \"HTTPValidationError\" , \"type\" : \"object\" , \"properties\" : { \"detail\" : { \"title\" : \"Detail\" , \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/ValidationError\" }, } }, }, } }, } resp = client . get ( \"/openapi.json\" ) assert resp . status_code == 200 , resp . content assert resp . json () == expected_openapi if __name__ == \"__main__\" : test_echo_item () test_openapi_schema () At this point we would have just stubbed out the actual implementations (just FromMsgPack for now, something like FromMsgPack = Annotated[T, \"placeholder\"] would do). So go ahead and create a file called functions.py and add a stub for FromMsgPack . But if we run our tests ( pytest tests.py ) they fail. So we need to actually cook up the implementations next.","title":"Tests"},{"location":"advanced/binders/#extractor","text":"We'll start with the extractors. Make a file called extractor.py with the following contents: import inspect import sys from typing import Any , NamedTuple , Type if sys . version_info < ( 3 , 8 ): from typing_extensions import get_args else : from typing import get_args import msgpack # type: ignore[import] from pydantic import BaseModel from xpresso import Request from xpresso.binders.api import SupportsBodyExtractor from xpresso.requests import HTTPConnection class MsgPackBodyExtractor ( NamedTuple ): model : Type [ BaseModel ] async def extract ( self , connection : HTTPConnection ) -> Any : assert isinstance ( connection , Request ) data = await connection . body () deserialized_obj : Any = msgpack . unpackb ( data ) # type: ignore[assignment] # You probably want more checks and validation here # For example, handling empty bodies # This is just a tutorial! return self . model . parse_obj ( deserialized_obj ) class MsgPackBodyExtractorMarker : def register_parameter ( self , param : inspect . Parameter ) -> SupportsBodyExtractor : # get the first paramater to Annotated, which should be our actual type model = next ( iter ( get_args ( param . annotation ))) if not issubclass ( model , BaseModel ): # You may want more rigourous checks here # Or you may want to accept non-Pydantic models # We do the easiest thing here raise TypeError ( \"MessagePack model must be a Pydantic model\" ) return MsgPackBodyExtractor ( model ) Tip All of these base classes are typing.Protocol classes. This means you do not actually have to inherit from them directly to implement them. But it can be helpful to do so to get IDE autocompletion on method signatures as you implement them.","title":"Extractor"},{"location":"advanced/binders/#openapiprovider","text":"This OpenAPIProvider will be somewhat anemic: there isn't much we can describe about MessagePack to OpenAPI other than the expected media type and that it will be binary data. Make a file called openapi.py with the following contents: import inspect import typing from xpresso.binders.api import ( ModelNameMap , Schemas , SupportsOpenAPIBody , ) from xpresso.openapi import models class OpenAPIBodyMsgPack : include_in_schema : bool = True media_type = \"application/x-msgpack\" def get_models ( self ) -> typing . List [ type ]: return [] def get_openapi_media_type ( self , model_name_map : ModelNameMap , schemas : Schemas ) -> models . MediaType : return models . MediaType ( schema = self . get_field_schema ( model_name_map , schemas ) ) def get_field_schema ( self , model_name_map : ModelNameMap , schemas : Schemas ) -> models . Schema : return models . Schema ( type = \"string\" , format = \"binary\" , ) def get_openapi_body ( self , model_name_map : ModelNameMap , schemas : Schemas ) -> models . RequestBody : return models . RequestBody ( content = { self . media_type : self . get_openapi_media_type ( model_name_map , schemas ) } ) def get_field_encoding ( self , model_name_map : ModelNameMap , schemas : Schemas ) -> models . Encoding : return models . Encoding ( contentType = self . media_type ) class OpenAPIBodyMarkerMsgPack : def register_parameter ( self , param : inspect . Parameter ) -> SupportsOpenAPIBody : return OpenAPIBodyMsgPack () You may notice that there are several pointless methods here that could have all been stuck into get_openapi() . These aren't strictly necessary here, but would be used if we tried to use this Binder as form field in a multipart/form-data request, so we are showing them to you just in case.","title":"OpenAPIProvider"},{"location":"advanced/binders/#putting-it-all-together","text":"Now we just need some sugar so we can call a single function and have it wire all of this stuff up. Open functions.py , remove your FromMsgPack stub and add: from typing import Any , TypeVar from xpresso.binders.dependants import BodyBinderMarker from xpresso.typing import Annotated from .extractor import MsgPackBodyExtractorMarker from .openapi import OpenAPIBodyMarkerMsgPack T = TypeVar ( \"T\" ) def MsgPack () -> Any : return BodyBinderMarker ( extractor_marker = MsgPackBodyExtractorMarker (), field_extractor_marker = None , openapi_marker = OpenAPIBodyMarkerMsgPack (), openapi_field_marker = None , ) FromMsgPack = Annotated [ T , MsgPack ()] You don't have to worry much about BodyBinderMarker . It's just a helper class that takes care of the interaction with the dependency injection system.","title":"Putting it all together"},{"location":"advanced/binders/#run-the-tests","text":"That's it! Now you can run the tests ( pytest tests.py ) and they should pass!","title":"Run the tests"},{"location":"advanced/proxies-root-path/","text":"Setting the root_path for your Xpresso App In most cases, when your app gets a request for https://example.com/v1/api/app the URL path will be /v1/api/app . But sometimes if you are running behind a reverse proxy or some other network layer that does routing based on the path, some prefix of the path may be stripped. For example, your proxy may be set up to direct traffic between /v1/api/app and /v2/api/app , and when it forwards the request to one of your applications, it may strip the /v{1,2}/api part of the path. This means your application would think that it is being called at /app when really the client is calling it at /v1/api/app . Amongst other problems, this means that your OpenAPI docs won't work as intended: when Xpresso generates the Swagger client that your browser loads (usually /docs ), it needs to inject it's own URL into it so that your browser can make a request back to the API to get the OpenAPI spec (usually /openapi.json ). If your app doesn't know about the /v1/api part of the path, it will tell the frontend (Swagger) to load /openapi.json , when it should have used /v1/api/openapi.json instead. To get around these situations, the ASGI specification uses a parameter called root_path . This is set by servers (like Uvicorn) or by your application. To set this value in Xpresso, use the root_path parameter to App : from xpresso import App , Path , Request def read_main ( request : Request ) -> str : return f \"Hello from { request . url_for ( 'main' ) } \" app = App ( routes = [ Path ( \"/app\" , get = read_main , name = \"main\" ), ], root_path = \"/v1/api\" , )","title":"Proxies and URL paths"},{"location":"advanced/proxies-root-path/#setting-the-root_path-for-your-xpresso-app","text":"In most cases, when your app gets a request for https://example.com/v1/api/app the URL path will be /v1/api/app . But sometimes if you are running behind a reverse proxy or some other network layer that does routing based on the path, some prefix of the path may be stripped. For example, your proxy may be set up to direct traffic between /v1/api/app and /v2/api/app , and when it forwards the request to one of your applications, it may strip the /v{1,2}/api part of the path. This means your application would think that it is being called at /app when really the client is calling it at /v1/api/app . Amongst other problems, this means that your OpenAPI docs won't work as intended: when Xpresso generates the Swagger client that your browser loads (usually /docs ), it needs to inject it's own URL into it so that your browser can make a request back to the API to get the OpenAPI spec (usually /openapi.json ). If your app doesn't know about the /v1/api part of the path, it will tell the frontend (Swagger) to load /openapi.json , when it should have used /v1/api/openapi.json instead. To get around these situations, the ASGI specification uses a parameter called root_path . This is set by servers (like Uvicorn) or by your application. To set this value in Xpresso, use the root_path parameter to App : from xpresso import App , Path , Request def read_main ( request : Request ) -> str : return f \"Hello from { request . url_for ( 'main' ) } \" app = App ( routes = [ Path ( \"/app\" , get = read_main , name = \"main\" ), ], root_path = \"/v1/api\" , )","title":"Setting the root_path for your Xpresso App"},{"location":"advanced/responses/","text":"Documenting OpenAPI responses So far we have mostly just let Xpresso infer the response model from type annotation. By default, Xpresso assumes the response is JSON serializable type and uses \"application/json\" with an HTTP 200 status code. You can also declare other responses or override the default response's status code, media type or schema. Adding an error response We can document a 404 response as follows: from typing import Any from pydantic import BaseModel from xpresso import App , FromPath , Operation , Path from xpresso.responses import JSONResponse , ResponseSpec class Item ( BaseModel ): id : str value : str class Message ( BaseModel ): message : str async def read_item ( item_id : FromPath [ str ]) -> Any : if item_id == \"foo\" : return { \"id\" : \"foo\" , \"value\" : \"there goes my hero\" } return JSONResponse ( status_code = 404 , content = { \"message\" : \"Item not found\" } ) get_item = Operation ( read_item , response_model = Item , responses = { 404 : ResponseSpec ( content = { \"application/json\" : Message }), }, ) app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item )]) Warning Notice that when you are returning a non-default status code, you must return an actual Response , not an arbitrary JSON serializable object. Adding media types to the default response from typing import Any , Optional from pydantic import BaseModel from xpresso import App , FromPath , Operation , Path from xpresso.parameters import FromQuery from xpresso.responses import Response , ResponseSpec class Item ( BaseModel ): id : str value : str async def read_item ( item_id : FromPath [ str ], img : FromQuery [ Optional [ bool ]] ) -> Any : if img : return Response ( b \"<image bytes>\" , media_type = \"image/png\" ) else : return { \"id\" : \"foo\" , \"value\" : \"there goes my hero\" } get_item = Operation ( read_item , responses = { 200 : ResponseSpec ( description = \"OK\" , content = { \"application/json\" : Item , \"image/png\" : bytes }, ) }, ) app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item )]) Tip We could have also specified the return type for the 200 status code via the default_response_model parameter to Operation . Either way, we had to specify it because our function returns Any (it could return Union[dict, Response] , the situation is the same) so Xpresso can't infer the right response model from type annotations. Changing the media type for the default response from xpresso import App , FromPath , Operation , Path , Response async def read_item ( item_id : FromPath [ str ]) -> bytes : return f \"<bytes from { item_id } .png>\" . encode () get_item = Operation ( read_item , response_media_type = \"image/png\" , response_encoder = None , response_factory = Response , ) app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item )]) Warning Just changing the media type does not change how the response gets encoded, so we also had to pass response_encoder=None to avoid encoding bytes as JSON! Changing the status code for the default response from pydantic import BaseModel from xpresso import App , Operation , Path , status class Item ( BaseModel ): id : str value : str async def create_item ( item : Item ) -> None : ... post_item = Operation ( create_item , response_status_code = status . HTTP_204_NO_CONTENT , ) app = App ( routes = [ Path ( \"/items/\" , post = post_item )]) Changing the default response status code via default_response_status_code changes the runtime behavior of our application in addition to the OpenAPI documentation: our endpoint will now return HTTP 201 responses. Responses on Router and Path You can also set responses on Router and Path, which will get merged into any responses defined for Operation. Responses for Operation take precedence over those of Path, and Path takes precedence over Routers. Status codes, media types and headers are merged. Examples and response models are overridden. from pydantic import BaseModel from xpresso import App , Operation , Path , status class Item ( BaseModel ): id : str value : str async def create_item ( item : Item ) -> None : ... post_item = Operation ( create_item , response_status_code = status . HTTP_204_NO_CONTENT , ) app = App ( routes = [ Path ( \"/items/\" , post = post_item )])","title":"Documenting OpenAPI responses"},{"location":"advanced/responses/#documenting-openapi-responses","text":"So far we have mostly just let Xpresso infer the response model from type annotation. By default, Xpresso assumes the response is JSON serializable type and uses \"application/json\" with an HTTP 200 status code. You can also declare other responses or override the default response's status code, media type or schema.","title":"Documenting OpenAPI responses"},{"location":"advanced/responses/#adding-an-error-response","text":"We can document a 404 response as follows: from typing import Any from pydantic import BaseModel from xpresso import App , FromPath , Operation , Path from xpresso.responses import JSONResponse , ResponseSpec class Item ( BaseModel ): id : str value : str class Message ( BaseModel ): message : str async def read_item ( item_id : FromPath [ str ]) -> Any : if item_id == \"foo\" : return { \"id\" : \"foo\" , \"value\" : \"there goes my hero\" } return JSONResponse ( status_code = 404 , content = { \"message\" : \"Item not found\" } ) get_item = Operation ( read_item , response_model = Item , responses = { 404 : ResponseSpec ( content = { \"application/json\" : Message }), }, ) app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item )]) Warning Notice that when you are returning a non-default status code, you must return an actual Response , not an arbitrary JSON serializable object.","title":"Adding an error response"},{"location":"advanced/responses/#adding-media-types-to-the-default-response","text":"from typing import Any , Optional from pydantic import BaseModel from xpresso import App , FromPath , Operation , Path from xpresso.parameters import FromQuery from xpresso.responses import Response , ResponseSpec class Item ( BaseModel ): id : str value : str async def read_item ( item_id : FromPath [ str ], img : FromQuery [ Optional [ bool ]] ) -> Any : if img : return Response ( b \"<image bytes>\" , media_type = \"image/png\" ) else : return { \"id\" : \"foo\" , \"value\" : \"there goes my hero\" } get_item = Operation ( read_item , responses = { 200 : ResponseSpec ( description = \"OK\" , content = { \"application/json\" : Item , \"image/png\" : bytes }, ) }, ) app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item )]) Tip We could have also specified the return type for the 200 status code via the default_response_model parameter to Operation . Either way, we had to specify it because our function returns Any (it could return Union[dict, Response] , the situation is the same) so Xpresso can't infer the right response model from type annotations.","title":"Adding media types to the default response"},{"location":"advanced/responses/#changing-the-media-type-for-the-default-response","text":"from xpresso import App , FromPath , Operation , Path , Response async def read_item ( item_id : FromPath [ str ]) -> bytes : return f \"<bytes from { item_id } .png>\" . encode () get_item = Operation ( read_item , response_media_type = \"image/png\" , response_encoder = None , response_factory = Response , ) app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item )]) Warning Just changing the media type does not change how the response gets encoded, so we also had to pass response_encoder=None to avoid encoding bytes as JSON!","title":"Changing the media type for the default response"},{"location":"advanced/responses/#changing-the-status-code-for-the-default-response","text":"from pydantic import BaseModel from xpresso import App , Operation , Path , status class Item ( BaseModel ): id : str value : str async def create_item ( item : Item ) -> None : ... post_item = Operation ( create_item , response_status_code = status . HTTP_204_NO_CONTENT , ) app = App ( routes = [ Path ( \"/items/\" , post = post_item )]) Changing the default response status code via default_response_status_code changes the runtime behavior of our application in addition to the OpenAPI documentation: our endpoint will now return HTTP 201 responses.","title":"Changing the status code for the default response"},{"location":"advanced/responses/#responses-on-router-and-path","text":"You can also set responses on Router and Path, which will get merged into any responses defined for Operation. Responses for Operation take precedence over those of Path, and Path takes precedence over Routers. Status codes, media types and headers are merged. Examples and response models are overridden. from pydantic import BaseModel from xpresso import App , Operation , Path , status class Item ( BaseModel ): id : str value : str async def create_item ( item : Item ) -> None : ... post_item = Operation ( create_item , response_status_code = status . HTTP_204_NO_CONTENT , ) app = App ( routes = [ Path ( \"/items/\" , post = post_item )])","title":"Responses on Router and Path"},{"location":"advanced/websockets/","text":"WebSockets Xpresso supports WebSockets via Starlette's WebSocket support . The only functionality added on top of Starlette's is the ability to inject HTTP parameters like headers: from xpresso import ( App , Depends , FromHeader , WebSocket , WebSocketRoute , ) from xpresso.exceptions import WebSocketValidationError async def enforce_header_pattern ( x_header : FromHeader [ int ], ws : WebSocket ) -> None : if not x_header > 0 : await ws . close () # This currently produces a 500 error in the server logs # See https://github.com/encode/starlette/pull/527 for more info raise WebSocketValidationError ([]) async def websocket_endpoint ( ws : WebSocket , x_header : FromHeader [ int ] ) -> None : await ws . accept () await ws . send_text ( str ( x_header )) await ws . close () app = App ( routes = [ WebSocketRoute ( path = \"/ws\" , endpoint = websocket_endpoint , dependencies = [ Depends ( enforce_header_pattern )], ), ] )","title":"WebSockets"},{"location":"advanced/websockets/#websockets","text":"Xpresso supports WebSockets via Starlette's WebSocket support . The only functionality added on top of Starlette's is the ability to inject HTTP parameters like headers: from xpresso import ( App , Depends , FromHeader , WebSocket , WebSocketRoute , ) from xpresso.exceptions import WebSocketValidationError async def enforce_header_pattern ( x_header : FromHeader [ int ], ws : WebSocket ) -> None : if not x_header > 0 : await ws . close () # This currently produces a 500 error in the server logs # See https://github.com/encode/starlette/pull/527 for more info raise WebSocketValidationError ([]) async def websocket_endpoint ( ws : WebSocket , x_header : FromHeader [ int ] ) -> None : await ws . accept () await ws . send_text ( str ( x_header )) await ws . close () app = App ( routes = [ WebSocketRoute ( path = \"/ws\" , endpoint = websocket_endpoint , dependencies = [ Depends ( enforce_header_pattern )], ), ] )","title":"WebSockets"},{"location":"advanced/dependencies/caching/","text":"Dependency Caching Xpresso has a dependency caching system. This allows re-using of already computed dependencies within a request response cycle. This is also what enables Xpresso to persist \"app\" scoped dependencies across requests (see Scopes ). By default, all dependencies are cached within their execution scope, but this can be disabled on a per-dependency basis with the use_cache argument to Depends . First we are going to declare a placeholder dependency with no sub-dependencies. We are just going to compare instances, so there's nothing else needed in this dependency. from xpresso import App , Depends , Path from xpresso.typing import Annotated class SharedDependency : pass def dependency_1 ( shared : SharedDependency ) -> SharedDependency : return shared def dependency_2 ( shared : SharedDependency ) -> SharedDependency : return shared async def endpoint ( shared1 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared2 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared3 : Annotated [ SharedDependency , Depends ( use_cache = False )], ) -> None : assert shared1 is shared2 assert shared1 is not shared3 app = App ( routes = [ Path ( \"/shared\" , get = endpoint , ) ] ) Next we'll create two dependencies that depend on this dependency to test that sub-dependencies are shared: from xpresso import App , Depends , Path from xpresso.typing import Annotated class SharedDependency : pass def dependency_1 ( shared : SharedDependency ) -> SharedDependency : return shared def dependency_2 ( shared : SharedDependency ) -> SharedDependency : return shared async def endpoint ( shared1 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared2 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared3 : Annotated [ SharedDependency , Depends ( use_cache = False )], ) -> None : assert shared1 is shared2 assert shared1 is not shared3 app = App ( routes = [ Path ( \"/shared\" , get = endpoint , ) ] ) Finally we create an endpoint that checks that the shared sub-dependencies are the same but the dependency declared with use_cache=False is not the same: from xpresso import App , Depends , Path from xpresso.typing import Annotated class SharedDependency : pass def dependency_1 ( shared : SharedDependency ) -> SharedDependency : return shared def dependency_2 ( shared : SharedDependency ) -> SharedDependency : return shared async def endpoint ( shared1 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared2 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared3 : Annotated [ SharedDependency , Depends ( use_cache = False )], ) -> None : assert shared1 is shared2 assert shared1 is not shared3 app = App ( routes = [ Path ( \"/shared\" , get = endpoint , ) ] ) You can test this by running the app and navigating to http://127.0.0.1:800/shared . You should get a 200 OK response with no errors.","title":"Caching"},{"location":"advanced/dependencies/caching/#dependency-caching","text":"Xpresso has a dependency caching system. This allows re-using of already computed dependencies within a request response cycle. This is also what enables Xpresso to persist \"app\" scoped dependencies across requests (see Scopes ). By default, all dependencies are cached within their execution scope, but this can be disabled on a per-dependency basis with the use_cache argument to Depends . First we are going to declare a placeholder dependency with no sub-dependencies. We are just going to compare instances, so there's nothing else needed in this dependency. from xpresso import App , Depends , Path from xpresso.typing import Annotated class SharedDependency : pass def dependency_1 ( shared : SharedDependency ) -> SharedDependency : return shared def dependency_2 ( shared : SharedDependency ) -> SharedDependency : return shared async def endpoint ( shared1 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared2 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared3 : Annotated [ SharedDependency , Depends ( use_cache = False )], ) -> None : assert shared1 is shared2 assert shared1 is not shared3 app = App ( routes = [ Path ( \"/shared\" , get = endpoint , ) ] ) Next we'll create two dependencies that depend on this dependency to test that sub-dependencies are shared: from xpresso import App , Depends , Path from xpresso.typing import Annotated class SharedDependency : pass def dependency_1 ( shared : SharedDependency ) -> SharedDependency : return shared def dependency_2 ( shared : SharedDependency ) -> SharedDependency : return shared async def endpoint ( shared1 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared2 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared3 : Annotated [ SharedDependency , Depends ( use_cache = False )], ) -> None : assert shared1 is shared2 assert shared1 is not shared3 app = App ( routes = [ Path ( \"/shared\" , get = endpoint , ) ] ) Finally we create an endpoint that checks that the shared sub-dependencies are the same but the dependency declared with use_cache=False is not the same: from xpresso import App , Depends , Path from xpresso.typing import Annotated class SharedDependency : pass def dependency_1 ( shared : SharedDependency ) -> SharedDependency : return shared def dependency_2 ( shared : SharedDependency ) -> SharedDependency : return shared async def endpoint ( shared1 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared2 : Annotated [ SharedDependency , Depends ( dependency_1 )], shared3 : Annotated [ SharedDependency , Depends ( use_cache = False )], ) -> None : assert shared1 is shared2 assert shared1 is not shared3 app = App ( routes = [ Path ( \"/shared\" , get = endpoint , ) ] ) You can test this by running the app and navigating to http://127.0.0.1:800/shared . You should get a 200 OK response with no errors.","title":"Dependency Caching"},{"location":"advanced/dependencies/overrides/","text":"Dependency Overrides We've already seen one way of telling the dependency injection system how to wire a dependency that it can't auto-wire in the form of Markers . There are however other situations where Markers may not be the answer. For these situations, Xpresso offers dependency overrides which lets you dynamically bind a provider to a dependency. When you override a dependency, you completely replace the original provider (if any) in Xpresso's directed acyclic graph of dependencies. This means that any sub-dependencies of the original provider (if any) will not be executed. This also means that the provider you are registering can itself have sub-dependencies. Those will get treated just like any other dependency, all of the same rules apply. As an example, let's look at how we might write a test for our ongoing httpx.AsyncClient examples. Here is the example we had previously from the Dependency Injection - Introduction section: import httpx from xpresso import App , Path async def echo_url ( client : httpx . AsyncClient ) -> str : resp = await client . get ( \"https://httpbin.org/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) We don't want to actually make network calls to HTTPBin in our tests, so we swap out the httpx.AsyncClient for one using httpx.MockTransport : import httpx from docs_src.tutorial.dependencies.tutorial_001 import app from xpresso.testclient import TestClient def test_client_injection (): async def handler ( request : httpx . Request ) -> httpx . Response : assert request . url == \"https://httpbin.org/get\" return httpx . Response ( 200 , json = { \"url\" : \"https://httpbin.org/get\" }) transport = httpx . MockTransport ( handler ) http_client = httpx . AsyncClient ( transport = transport ) with app . dependency_overrides : app . dependency_overrides [ httpx . AsyncClient ] = lambda : http_client client = TestClient ( app ) response = client . get ( \"/echo/url\" ) assert response . status_code == 200 , response . content assert response . json () == \"https://httpbin.org/get\" Tip You can use app.dependency_overrides both as a context manager (like in the example above) and as a regular mapping-like object. If used as a context manager, the binding will be reversed when the context manager exits. Otherwise, the bind is permanent. You probably should use the context manager form in tests so that you don't leak state from one test to another. Tip Notice how we used a lambda to always return the same instance. Depending on what your dependency is, and what scope it was declared with, you may want to return a new instance each time. Note Xpresso's app.dependency_overrides is just a wrapper around the more advanced functionality offered in di . The lowest level, but most powerful, interface is Container.register_hook ( App.container.register_hook when accessed from an Xpresso App). See di's provider binding docs for more details. You can also use this same mechanism to declare a dependency on an abstract interface (including typing.Protocol classes) and then register a concrete implementation in some create_production_app() class and a different concrete implementation in create_test_app() .","title":"Dependency Overrides"},{"location":"advanced/dependencies/overrides/#dependency-overrides","text":"We've already seen one way of telling the dependency injection system how to wire a dependency that it can't auto-wire in the form of Markers . There are however other situations where Markers may not be the answer. For these situations, Xpresso offers dependency overrides which lets you dynamically bind a provider to a dependency. When you override a dependency, you completely replace the original provider (if any) in Xpresso's directed acyclic graph of dependencies. This means that any sub-dependencies of the original provider (if any) will not be executed. This also means that the provider you are registering can itself have sub-dependencies. Those will get treated just like any other dependency, all of the same rules apply. As an example, let's look at how we might write a test for our ongoing httpx.AsyncClient examples. Here is the example we had previously from the Dependency Injection - Introduction section: import httpx from xpresso import App , Path async def echo_url ( client : httpx . AsyncClient ) -> str : resp = await client . get ( \"https://httpbin.org/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) We don't want to actually make network calls to HTTPBin in our tests, so we swap out the httpx.AsyncClient for one using httpx.MockTransport : import httpx from docs_src.tutorial.dependencies.tutorial_001 import app from xpresso.testclient import TestClient def test_client_injection (): async def handler ( request : httpx . Request ) -> httpx . Response : assert request . url == \"https://httpbin.org/get\" return httpx . Response ( 200 , json = { \"url\" : \"https://httpbin.org/get\" }) transport = httpx . MockTransport ( handler ) http_client = httpx . AsyncClient ( transport = transport ) with app . dependency_overrides : app . dependency_overrides [ httpx . AsyncClient ] = lambda : http_client client = TestClient ( app ) response = client . get ( \"/echo/url\" ) assert response . status_code == 200 , response . content assert response . json () == \"https://httpbin.org/get\" Tip You can use app.dependency_overrides both as a context manager (like in the example above) and as a regular mapping-like object. If used as a context manager, the binding will be reversed when the context manager exits. Otherwise, the bind is permanent. You probably should use the context manager form in tests so that you don't leak state from one test to another. Tip Notice how we used a lambda to always return the same instance. Depending on what your dependency is, and what scope it was declared with, you may want to return a new instance each time. Note Xpresso's app.dependency_overrides is just a wrapper around the more advanced functionality offered in di . The lowest level, but most powerful, interface is Container.register_hook ( App.container.register_hook when accessed from an Xpresso App). See di's provider binding docs for more details. You can also use this same mechanism to declare a dependency on an abstract interface (including typing.Protocol classes) and then register a concrete implementation in some create_production_app() class and a different concrete implementation in create_test_app() .","title":"Dependency Overrides"},{"location":"advanced/dependencies/performance/","text":"Dependency Execution Performance Xpresso's dependency injection system lets you mix and match sync and async dependencies, use dependencies with teardown and control concurrency of dependency execution. If you want to get the best performance out of your system, you should understand how all of these features interact and profile different arrangements until you find the one that performs the best for you. Sync vs. Async The dependency injection system lets you mix and match sync and async dependencies. That is, a sync dependency can depend on an async one and vise versa. The main thing to keep in mind here is that by default dependencies are all executed in the same thread and event loop. This means that sync dependencies will block the event loop : a single sync dependency doing IO can bring your app to a grinding halt and make it unable to serve concurrent requests to other users. Fortunately, this is not a problem for many sync dependencies: if you are just loading a config from environment variables or otherwise not doing IO, your sync dependency won't \"block\" the event loop and your app will run fine. When you really need to start worrying about things is if you are doing database IO with a synchronous database client or something like that. For these cases, Xpresso provides a sync_to_thread argument to Depends as well as Operation . This will move execution of this dependency or endpoint function into a thread so that it can do IO concurrently and not block your application. For example, let's make a sync endpoint and sync dependencies that call time.sleep() to simulate some sort of blocking IO: import time from xpresso import App , Depends , Operation , Path def slow_dependency () -> None : time . sleep ( 1e-3 ) def slow_endpoint () -> None : time . sleep ( 1e-3 ) app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = slow_endpoint , sync_to_thread = True , dependencies = [ Depends ( slow_dependency , sync_to_thread = True ) ], ), ) ] ) All we have to do is pass sync_to_thread=True in the right place to signal that the endpoint function or dependency should be executed in a thread: import time from xpresso import App , Depends , Operation , Path def slow_dependency () -> None : time . sleep ( 1e-3 ) def slow_endpoint () -> None : time . sleep ( 1e-3 ) app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = slow_endpoint , sync_to_thread = True , dependencies = [ Depends ( slow_dependency , sync_to_thread = True ) ], ), ) ] ) The endpoint will still take ~200ms to return a result, but at least it won't block the entire application from handling other requests. Tip This does not do anything about the global interpreter lock (GIL). Long running CPU bound computation, like inference on a machine learning model, will still block your application (it will block the entire Python process). For these situations, consider using Gunicorn to manage multiple processes or create a subprocess manually just for that CPU intensive computation. Warning There is an overhead to using sync_to_thread , hence why it is not the default. Do not blindly use it on every sync dependency, profile first! Concurrent execution Xpresso is capable of enabling concurrent execution of dependencies. For example, if you have a dependency that gets the current user from the database and another that (independently) makes an HTTP request to an authorization server to check if the user's credentials are still active, these can be executed concurrently. If each dependency takes 100ms to execute, this means together they will only take ~100ms to execute instead of 200ms. The key is that there must be no interdependence between them and they must both be IO bound (including sync dependencies marked with sync_to_thread ). To turn on concurrent execution of dependencies, use the execute_dependencies_concurrently argument to Operation . First we'll define two placeholder dependencies that do not depend on each other: import time import anyio from xpresso import App , Depends , Operation , Path def slow_dependency_1 () -> None : time . sleep ( 1 ) async def slow_dependency_2 () -> None : await anyio . sleep ( 1 ) async def endpoint () -> None : ... app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = endpoint , dependencies = [ Depends ( slow_dependency_1 , sync_to_thread = True ), Depends ( slow_dependency_2 ), ], execute_dependencies_concurrently = True , ), ) ] ) Then we'll create an Operation that uses these two dependencies: import time import anyio from xpresso import App , Depends , Operation , Path def slow_dependency_1 () -> None : time . sleep ( 1 ) async def slow_dependency_2 () -> None : await anyio . sleep ( 1 ) async def endpoint () -> None : ... app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = endpoint , dependencies = [ Depends ( slow_dependency_1 , sync_to_thread = True ), Depends ( slow_dependency_2 ), ], execute_dependencies_concurrently = True , ), ) ] ) And finally we pass execute_dependencies_concurrently=True to Operation: import time import anyio from xpresso import App , Depends , Operation , Path def slow_dependency_1 () -> None : time . sleep ( 1 ) async def slow_dependency_2 () -> None : await anyio . sleep ( 1 ) async def endpoint () -> None : ... app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = endpoint , dependencies = [ Depends ( slow_dependency_1 , sync_to_thread = True ), Depends ( slow_dependency_2 ), ], execute_dependencies_concurrently = True , ), ) ] ) That's it! Now this endpoint will take ~0.1s to execute instead of 0.2s. Tip You can only enable or disable concurrent execution for an entire Operation. This can't be applied to groups of dependencies individually. Note There is no guarantee of ordering of execution. The most efficient execution path is calculated at runtime using the algorithm described in the standard library's graphlib re-implemented in Rust by graphlib2 . The actual concurrency is enabled by anyio TaskGroups . Warning There is overhead to enabling this feature. For simple endpoints that don't benefit from concurrency of dependency execution, this will likely hurt performance. Always profile before applying this option! Attention Teardowns are never executed concurrently or in threads. You should try to avoid doing expensive IO in teardowns, they are mean for error handling and cleaning up resources.","title":"Performance"},{"location":"advanced/dependencies/performance/#dependency-execution-performance","text":"Xpresso's dependency injection system lets you mix and match sync and async dependencies, use dependencies with teardown and control concurrency of dependency execution. If you want to get the best performance out of your system, you should understand how all of these features interact and profile different arrangements until you find the one that performs the best for you.","title":"Dependency Execution Performance"},{"location":"advanced/dependencies/performance/#sync-vs-async","text":"The dependency injection system lets you mix and match sync and async dependencies. That is, a sync dependency can depend on an async one and vise versa. The main thing to keep in mind here is that by default dependencies are all executed in the same thread and event loop. This means that sync dependencies will block the event loop : a single sync dependency doing IO can bring your app to a grinding halt and make it unable to serve concurrent requests to other users. Fortunately, this is not a problem for many sync dependencies: if you are just loading a config from environment variables or otherwise not doing IO, your sync dependency won't \"block\" the event loop and your app will run fine. When you really need to start worrying about things is if you are doing database IO with a synchronous database client or something like that. For these cases, Xpresso provides a sync_to_thread argument to Depends as well as Operation . This will move execution of this dependency or endpoint function into a thread so that it can do IO concurrently and not block your application. For example, let's make a sync endpoint and sync dependencies that call time.sleep() to simulate some sort of blocking IO: import time from xpresso import App , Depends , Operation , Path def slow_dependency () -> None : time . sleep ( 1e-3 ) def slow_endpoint () -> None : time . sleep ( 1e-3 ) app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = slow_endpoint , sync_to_thread = True , dependencies = [ Depends ( slow_dependency , sync_to_thread = True ) ], ), ) ] ) All we have to do is pass sync_to_thread=True in the right place to signal that the endpoint function or dependency should be executed in a thread: import time from xpresso import App , Depends , Operation , Path def slow_dependency () -> None : time . sleep ( 1e-3 ) def slow_endpoint () -> None : time . sleep ( 1e-3 ) app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = slow_endpoint , sync_to_thread = True , dependencies = [ Depends ( slow_dependency , sync_to_thread = True ) ], ), ) ] ) The endpoint will still take ~200ms to return a result, but at least it won't block the entire application from handling other requests. Tip This does not do anything about the global interpreter lock (GIL). Long running CPU bound computation, like inference on a machine learning model, will still block your application (it will block the entire Python process). For these situations, consider using Gunicorn to manage multiple processes or create a subprocess manually just for that CPU intensive computation. Warning There is an overhead to using sync_to_thread , hence why it is not the default. Do not blindly use it on every sync dependency, profile first!","title":"Sync vs. Async"},{"location":"advanced/dependencies/performance/#concurrent-execution","text":"Xpresso is capable of enabling concurrent execution of dependencies. For example, if you have a dependency that gets the current user from the database and another that (independently) makes an HTTP request to an authorization server to check if the user's credentials are still active, these can be executed concurrently. If each dependency takes 100ms to execute, this means together they will only take ~100ms to execute instead of 200ms. The key is that there must be no interdependence between them and they must both be IO bound (including sync dependencies marked with sync_to_thread ). To turn on concurrent execution of dependencies, use the execute_dependencies_concurrently argument to Operation . First we'll define two placeholder dependencies that do not depend on each other: import time import anyio from xpresso import App , Depends , Operation , Path def slow_dependency_1 () -> None : time . sleep ( 1 ) async def slow_dependency_2 () -> None : await anyio . sleep ( 1 ) async def endpoint () -> None : ... app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = endpoint , dependencies = [ Depends ( slow_dependency_1 , sync_to_thread = True ), Depends ( slow_dependency_2 ), ], execute_dependencies_concurrently = True , ), ) ] ) Then we'll create an Operation that uses these two dependencies: import time import anyio from xpresso import App , Depends , Operation , Path def slow_dependency_1 () -> None : time . sleep ( 1 ) async def slow_dependency_2 () -> None : await anyio . sleep ( 1 ) async def endpoint () -> None : ... app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = endpoint , dependencies = [ Depends ( slow_dependency_1 , sync_to_thread = True ), Depends ( slow_dependency_2 ), ], execute_dependencies_concurrently = True , ), ) ] ) And finally we pass execute_dependencies_concurrently=True to Operation: import time import anyio from xpresso import App , Depends , Operation , Path def slow_dependency_1 () -> None : time . sleep ( 1 ) async def slow_dependency_2 () -> None : await anyio . sleep ( 1 ) async def endpoint () -> None : ... app = App ( routes = [ Path ( \"/slow\" , get = Operation ( endpoint = endpoint , dependencies = [ Depends ( slow_dependency_1 , sync_to_thread = True ), Depends ( slow_dependency_2 ), ], execute_dependencies_concurrently = True , ), ) ] ) That's it! Now this endpoint will take ~0.1s to execute instead of 0.2s. Tip You can only enable or disable concurrent execution for an entire Operation. This can't be applied to groups of dependencies individually. Note There is no guarantee of ordering of execution. The most efficient execution path is calculated at runtime using the algorithm described in the standard library's graphlib re-implemented in Rust by graphlib2 . The actual concurrency is enabled by anyio TaskGroups . Warning There is overhead to enabling this feature. For simple endpoints that don't benefit from concurrency of dependency execution, this will likely hurt performance. Always profile before applying this option! Attention Teardowns are never executed concurrently or in threads. You should try to avoid doing expensive IO in teardowns, they are mean for error handling and cleaning up resources.","title":"Concurrent execution"},{"location":"advanced/dependencies/responses/","text":"Accessing Responses from Dependencies Xpresso gives you the ability to access and even modify responses from within dependencies. You will be able to: Get a reference to the response returned by the endpoint function Modify that response in place Replace that response with a completely different response object This functionality is enabled through response proxies : xpresso.responses.get_response(request: Request) -> Response xpresso.responses.set_response(request: Request, response: Response) -> None These functions can only be called from within the teardown of a dependency. If called from anywhere else (inside the endpoint or in the setup of a context manager dependency) they will raise an exception. Further, modifying the response or calling set_response() will only work from a dependency in the \"endpoint\" scope (otherwise the response has already been sent). Reading responses Here is an example of a dependency that logs the status code for every response on a path: from typing import Generator , List from xpresso import ( App , Depends , FromPath , HTTPException , Path , Request , ) from xpresso.responses import get_response class StatusCodeLogFile ( List [ int ]): pass def log_response_status_code ( request : Request , log : StatusCodeLogFile ) -> Generator [ None , None , None ]: try : yield except HTTPException as exc : log . append ( exc . status_code ) raise else : response = get_response ( request ) log . append ( response . status_code ) fake_items_db = { \"foo\" : \"Foo\" , \"bar\" : \"Bar\" } async def read_items ( item_name : FromPath [ str ]) -> str : if item_name in fake_items_db : return fake_items_db [ item_name ] raise HTTPException ( status_code = 404 ) app = App ( routes = [ Path ( path = \"/items/ {item_name} \" , get = read_items , dependencies = [ Depends ( log_response_status_code , scope = \"connection\" ) ], ), ] ) If your dependency has the \"connection\" scope (like in the example above) you will be able to get a copy of the request, but attempting to modify it or replace it will have no result since it was already sent to the client. The main advantage of using the \"connection\" scope is reduced latency for the client. Writing responses If you need to modify the response, use the \"endpoint\" scope. Here's an example of a simple request/context tracing system: from typing import Generator from uuid import UUID , uuid4 from xpresso import ( App , Depends , FromPath , HTTPException , Path , Request , ) from xpresso.responses import get_response CONTEXT_HEADER = \"X-Request-Context\" def trace ( request : Request ) -> Generator [ None , None , None ]: req_ctx = request . headers . get ( CONTEXT_HEADER , None ) if req_ctx is not None : ctx = UUID ( req_ctx ) else : ctx = uuid4 () try : yield except HTTPException as exc : exc . headers [ CONTEXT_HEADER ] = str ( ctx ) raise else : response = get_response ( request ) response . headers [ CONTEXT_HEADER ] = str ( ctx ) fake_items_db = { \"foo\" : \"Foo\" , \"bar\" : \"Bar\" } async def read_items ( item_name : FromPath [ str ]) -> str : if item_name in fake_items_db : return fake_items_db [ item_name ] raise HTTPException ( status_code = 404 ) app = App ( routes = [ Path ( path = \"/items/ {item_name} \" , get = read_items , dependencies = [ Depends ( trace , scope = \"endpoint\" )], ), ] )","title":"Accessing Responses"},{"location":"advanced/dependencies/responses/#accessing-responses-from-dependencies","text":"Xpresso gives you the ability to access and even modify responses from within dependencies. You will be able to: Get a reference to the response returned by the endpoint function Modify that response in place Replace that response with a completely different response object This functionality is enabled through response proxies : xpresso.responses.get_response(request: Request) -> Response xpresso.responses.set_response(request: Request, response: Response) -> None These functions can only be called from within the teardown of a dependency. If called from anywhere else (inside the endpoint or in the setup of a context manager dependency) they will raise an exception. Further, modifying the response or calling set_response() will only work from a dependency in the \"endpoint\" scope (otherwise the response has already been sent).","title":"Accessing Responses from Dependencies"},{"location":"advanced/dependencies/responses/#reading-responses","text":"Here is an example of a dependency that logs the status code for every response on a path: from typing import Generator , List from xpresso import ( App , Depends , FromPath , HTTPException , Path , Request , ) from xpresso.responses import get_response class StatusCodeLogFile ( List [ int ]): pass def log_response_status_code ( request : Request , log : StatusCodeLogFile ) -> Generator [ None , None , None ]: try : yield except HTTPException as exc : log . append ( exc . status_code ) raise else : response = get_response ( request ) log . append ( response . status_code ) fake_items_db = { \"foo\" : \"Foo\" , \"bar\" : \"Bar\" } async def read_items ( item_name : FromPath [ str ]) -> str : if item_name in fake_items_db : return fake_items_db [ item_name ] raise HTTPException ( status_code = 404 ) app = App ( routes = [ Path ( path = \"/items/ {item_name} \" , get = read_items , dependencies = [ Depends ( log_response_status_code , scope = \"connection\" ) ], ), ] ) If your dependency has the \"connection\" scope (like in the example above) you will be able to get a copy of the request, but attempting to modify it or replace it will have no result since it was already sent to the client. The main advantage of using the \"connection\" scope is reduced latency for the client.","title":"Reading responses"},{"location":"advanced/dependencies/responses/#writing-responses","text":"If you need to modify the response, use the \"endpoint\" scope. Here's an example of a simple request/context tracing system: from typing import Generator from uuid import UUID , uuid4 from xpresso import ( App , Depends , FromPath , HTTPException , Path , Request , ) from xpresso.responses import get_response CONTEXT_HEADER = \"X-Request-Context\" def trace ( request : Request ) -> Generator [ None , None , None ]: req_ctx = request . headers . get ( CONTEXT_HEADER , None ) if req_ctx is not None : ctx = UUID ( req_ctx ) else : ctx = uuid4 () try : yield except HTTPException as exc : exc . headers [ CONTEXT_HEADER ] = str ( ctx ) raise else : response = get_response ( request ) response . headers [ CONTEXT_HEADER ] = str ( ctx ) fake_items_db = { \"foo\" : \"Foo\" , \"bar\" : \"Bar\" } async def read_items ( item_name : FromPath [ str ]) -> str : if item_name in fake_items_db : return fake_items_db [ item_name ] raise HTTPException ( status_code = 404 ) app = App ( routes = [ Path ( path = \"/items/ {item_name} \" , get = read_items , dependencies = [ Depends ( trace , scope = \"endpoint\" )], ), ] )","title":"Writing responses"},{"location":"tutorial/body/","text":"Request Body Xpresso has a rich system of extractors to extract and parse request bodies. These help give you type safety, data validation and automatic OpenAPI spec generation. We'll start off using JSON as an example since this is one of the most common types of request bodies. But as you will see in the later chapters, a lot of the same concepts apply forms and multipart requests. Declaring a body schema First, we need to define the schema of our body and give Xpresso a data structure to extract our body into. This data structure can be a built in type (like int or str ), a collection (like dict or list ) or a Pydantic model. Info Although Xpresso makes extensive use of Pydantic and no other similar libraries are supported out of the box, there is no reason why support could not be implemented. As you will see later, writing a custom extractor is pretty easy. It just doesn't make sense to provide out of the box integration with dozens of libraries, so we chose Pydantic. For most use cases, you'll want to stick with a Pydantic model. Declaring a Pydantic model is simple. Start by importing BaseModel from Pydantic and declaring the fields of the model using type annotations: from typing import Dict , Optional from pydantic import BaseModel from xpresso import App , FromJson , Path class Item ( BaseModel ): name : str price : float tax : Optional [ float ] = None async def create_receipt ( item : FromJson [ Item ]) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) Then we declare add the FromJson[...] marker (which is syntactic sugar for Annotated[..., Json()] ) to a paramter in our endpoint function: from typing import Dict , Optional from pydantic import BaseModel from xpresso import App , FromJson , Path class Item ( BaseModel ): name : str price : float tax : Optional [ float ] = None async def create_receipt ( item : FromJson [ Item ]) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) That's it! Now when you receive a request it will be read as JSON and then passed to Pydantic for validation and parsing. Your function will receive a validated instance of Item . OpenAPI and SwaggerUI Just like path and query parameters, request bodies automatically generate OpenAPI documentation: Constraints and Customization Pydantic supports rich validation and customization of model schemas. For in depth information on the topic, see Pydantic 's docs. But here is a quick example of how this can work in Xpresso. First, import Field from Pydantic and Annotated : from typing import Dict , Optional from pydantic import BaseModel , Field from xpresso import App , FromJson , Path from xpresso.typing import Annotated class Item ( BaseModel ): name : str price : Annotated [ float , Field ( gt = 0 , description = \"Item price without tax. Must be greater than zero.\" , ), ] tax : Optional [ float ] = None async def create_receipt ( item : FromJson [ Item ]) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) Tip The import from Xpresso.typing import Annotated is just a convenience import. All it does is import Annotated from typing if your Python version is >= 3.9 and [typing_extensions] otherwise. But if you are already using Python >= 3.9, you can just replace that with from typing import Annotated . Now use Field() inside of Annotated[...] to attach validation and schema customziation metadata to the price field: from typing import Dict , Optional from pydantic import BaseModel , Field from xpresso import App , FromJson , Path from xpresso.typing import Annotated class Item ( BaseModel ): name : str price : Annotated [ float , Field ( gt = 0 , description = \"Item price without tax. Must be greater than zero.\" , ), ] tax : Optional [ float ] = None async def create_receipt ( item : FromJson [ Item ]) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) Tip Pydantic also supports the syntax field_name: str = Field(...) , but we encourage youto get used to using Annotated instead. As you will see in later chapters about forms and multipart requests, this will allow you to mix in Pydantic's validation and schema customization with Xpresso's extractor system. That said, for JSON bodies using field_name: str = Field(...) will work just fine. Using builtin types While you will probably need Pydantic models for complex cases, in many simple cases you can get away with just using the standard library's container types. For example, you can declare that a JSON body is a list of integers: from typing import Dict , List from xpresso import App , FromJson , Path async def count_items ( item_counts : FromJson [ List [ int ]], ) -> Dict [ str , int ]: return { \"total\" : sum ( item_counts )} app = App ( routes = [ Path ( \"/items/count\" , put = count_items , ) ] ) Mixing builtins with Pydantic You can also wrap an existing Pydantic model in a container, for example to receive a list of items: from typing import Dict , List , Optional from pydantic import BaseModel from xpresso import App , FromJson , Path class Item ( BaseModel ): name : str price : float tax : Optional [ float ] = None async def create_receipt ( items : FromJson [ List [ Item ]], ) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 ) for item in items } app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) Including examples You can add examples via the examples keyword to Json() , FormData() or Multipart() : from typing import Dict , Optional from pydantic import BaseModel from xpresso import App , Json , Path from xpresso.typing import Annotated class Item ( BaseModel ): name : str price : float tax : Optional [ float ] = None item_examples = { \"With tax\" : Item ( name = \"foo\" , price = 1 , tax = 1 ), \"Duty Free\" : Item ( name = \"foo\" , price = 2 , tax = 0 ), } async def create_receipt ( item : Annotated [ Item , Json ( examples = item_examples )] ) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) The Swagger docs will now reflect this:","title":"Request Body"},{"location":"tutorial/body/#request-body","text":"Xpresso has a rich system of extractors to extract and parse request bodies. These help give you type safety, data validation and automatic OpenAPI spec generation. We'll start off using JSON as an example since this is one of the most common types of request bodies. But as you will see in the later chapters, a lot of the same concepts apply forms and multipart requests.","title":"Request Body"},{"location":"tutorial/body/#declaring-a-body-schema","text":"First, we need to define the schema of our body and give Xpresso a data structure to extract our body into. This data structure can be a built in type (like int or str ), a collection (like dict or list ) or a Pydantic model. Info Although Xpresso makes extensive use of Pydantic and no other similar libraries are supported out of the box, there is no reason why support could not be implemented. As you will see later, writing a custom extractor is pretty easy. It just doesn't make sense to provide out of the box integration with dozens of libraries, so we chose Pydantic. For most use cases, you'll want to stick with a Pydantic model. Declaring a Pydantic model is simple. Start by importing BaseModel from Pydantic and declaring the fields of the model using type annotations: from typing import Dict , Optional from pydantic import BaseModel from xpresso import App , FromJson , Path class Item ( BaseModel ): name : str price : float tax : Optional [ float ] = None async def create_receipt ( item : FromJson [ Item ]) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) Then we declare add the FromJson[...] marker (which is syntactic sugar for Annotated[..., Json()] ) to a paramter in our endpoint function: from typing import Dict , Optional from pydantic import BaseModel from xpresso import App , FromJson , Path class Item ( BaseModel ): name : str price : float tax : Optional [ float ] = None async def create_receipt ( item : FromJson [ Item ]) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) That's it! Now when you receive a request it will be read as JSON and then passed to Pydantic for validation and parsing. Your function will receive a validated instance of Item .","title":"Declaring a body schema"},{"location":"tutorial/body/#openapi-and-swaggerui","text":"Just like path and query parameters, request bodies automatically generate OpenAPI documentation:","title":"OpenAPI and SwaggerUI"},{"location":"tutorial/body/#constraints-and-customization","text":"Pydantic supports rich validation and customization of model schemas. For in depth information on the topic, see Pydantic 's docs. But here is a quick example of how this can work in Xpresso. First, import Field from Pydantic and Annotated : from typing import Dict , Optional from pydantic import BaseModel , Field from xpresso import App , FromJson , Path from xpresso.typing import Annotated class Item ( BaseModel ): name : str price : Annotated [ float , Field ( gt = 0 , description = \"Item price without tax. Must be greater than zero.\" , ), ] tax : Optional [ float ] = None async def create_receipt ( item : FromJson [ Item ]) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) Tip The import from Xpresso.typing import Annotated is just a convenience import. All it does is import Annotated from typing if your Python version is >= 3.9 and [typing_extensions] otherwise. But if you are already using Python >= 3.9, you can just replace that with from typing import Annotated . Now use Field() inside of Annotated[...] to attach validation and schema customziation metadata to the price field: from typing import Dict , Optional from pydantic import BaseModel , Field from xpresso import App , FromJson , Path from xpresso.typing import Annotated class Item ( BaseModel ): name : str price : Annotated [ float , Field ( gt = 0 , description = \"Item price without tax. Must be greater than zero.\" , ), ] tax : Optional [ float ] = None async def create_receipt ( item : FromJson [ Item ]) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) Tip Pydantic also supports the syntax field_name: str = Field(...) , but we encourage youto get used to using Annotated instead. As you will see in later chapters about forms and multipart requests, this will allow you to mix in Pydantic's validation and schema customization with Xpresso's extractor system. That said, for JSON bodies using field_name: str = Field(...) will work just fine.","title":"Constraints and Customization"},{"location":"tutorial/body/#using-builtin-types","text":"While you will probably need Pydantic models for complex cases, in many simple cases you can get away with just using the standard library's container types. For example, you can declare that a JSON body is a list of integers: from typing import Dict , List from xpresso import App , FromJson , Path async def count_items ( item_counts : FromJson [ List [ int ]], ) -> Dict [ str , int ]: return { \"total\" : sum ( item_counts )} app = App ( routes = [ Path ( \"/items/count\" , put = count_items , ) ] )","title":"Using builtin types"},{"location":"tutorial/body/#mixing-builtins-with-pydantic","text":"You can also wrap an existing Pydantic model in a container, for example to receive a list of items: from typing import Dict , List , Optional from pydantic import BaseModel from xpresso import App , FromJson , Path class Item ( BaseModel ): name : str price : float tax : Optional [ float ] = None async def create_receipt ( items : FromJson [ List [ Item ]], ) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 ) for item in items } app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] )","title":"Mixing builtins with Pydantic"},{"location":"tutorial/body/#including-examples","text":"You can add examples via the examples keyword to Json() , FormData() or Multipart() : from typing import Dict , Optional from pydantic import BaseModel from xpresso import App , Json , Path from xpresso.typing import Annotated class Item ( BaseModel ): name : str price : float tax : Optional [ float ] = None item_examples = { \"With tax\" : Item ( name = \"foo\" , price = 1 , tax = 1 ), \"Duty Free\" : Item ( name = \"foo\" , price = 2 , tax = 0 ), } async def create_receipt ( item : Annotated [ Item , Json ( examples = item_examples )] ) -> Dict [ str , float ]: return { item . name : item . price + ( item . tax or 0 )} app = App ( routes = [ Path ( \"/items/\" , post = create_receipt , ) ] ) The Swagger docs will now reflect this:","title":"Including examples"},{"location":"tutorial/cookie_params/","text":"Cookie Parameters Cookies parameters are declared the same way as Query and Path parameters: from typing import Dict , Optional from xpresso import App , FromCookie , Path async def read_items ( advertiser_id : FromCookie [ Optional [ int ]] = None , ) -> Dict [ str , Optional [ int ]]: return { \"advertiser_id\" : advertiser_id } app = App ( routes = [ Path ( \"/items/\" , get = read_items , ) ] ) Repeated Cookies Serialization and Parsing","title":"Cookie Parameters"},{"location":"tutorial/cookie_params/#cookie-parameters","text":"Cookies parameters are declared the same way as Query and Path parameters: from typing import Dict , Optional from xpresso import App , FromCookie , Path async def read_items ( advertiser_id : FromCookie [ Optional [ int ]] = None , ) -> Dict [ str , Optional [ int ]]: return { \"advertiser_id\" : advertiser_id } app = App ( routes = [ Path ( \"/items/\" , get = read_items , ) ] )","title":"Cookie Parameters"},{"location":"tutorial/cookie_params/#repeated-cookies","text":"","title":"Repeated Cookies"},{"location":"tutorial/cookie_params/#serialization-and-parsing","text":"","title":"Serialization and Parsing"},{"location":"tutorial/files/","text":"Files You can read the request body directly into a file or bytes. This will read the data from the top level request body, and can only support 1 file. To receive multiple files, see the multipart/form-data documentation . from xpresso import App , FromFile , Path , UploadFile async def count_bytes_in_file ( file : FromFile [ UploadFile ]) -> int : return len ( await file . read ()) app = App ( routes = [ Path ( path = \"/count-bytes\" , put = count_bytes_in_file )]) Note UploadFile is a class provided by Starlette that buffers the data in memory and overflows to disk if the data is larger than a predefined threshold. This prevents a large file from exhausting your hardware's memory, but does use disk space and CPU cycles for buffering. Implementation detail xpresso.UploadFile is just a thin wrapper around starlette.datastructures.UploadFile , but you must use xpresso.UploadFile instead of starlette.datastructures.UploadFile directly, otherwise Xpresso won't know how to build the argument. As bytes Xpresso can read the entire file into memory if you'd like: from xpresso import App , FromFile , Path async def count_bytes_in_file ( data : FromFile [ bytes ]) -> int : return len ( data ) app = App ( routes = [ Path ( path = \"/count-bytes\" , put = count_bytes_in_file )]) This can be convenient if you know the files are not large. As a stream If you want to read the bytes without buffering to disk or memory, use xpresso.BinaryStream as the type: from xpresso import App , BinaryStream , FromFile , Path async def count_bytes_in_file ( data : FromFile [ BinaryStream ]) -> int : size = 0 async for chunk in data : size += len ( chunk ) return size app = App ( routes = [ Path ( path = \"/count-bytes\" , put = count_bytes_in_file )]) Implementation detail xpresso.BinaryStream is just a thin wrapper around typing.AsyncIterator[bytes] , but you must use xpresso.BinaryStream instead of typing.AsyncIterator[bytes] directly, otherwise Xpresso won't know how to build the argument. Setting the expected content-type You can set the media type via the media_type parameter to File() and enforce it via the enforce_media_type parameter: from xpresso import App , File , Path , UploadFile from xpresso.typing import Annotated async def count_image_bytes ( file : Annotated [ UploadFile , File ( media_type = \"image/*\" , enforce_media_type = True ), ] ) -> int : return len ( await file . read ()) app = App ( routes = [ Path ( path = \"/count-bytes\" , put = count_image_bytes )]) Media types can be a media type (e.g. image/png ) or a media type range (e.g. image/* ). If you do not explicitly set the media type, all media types are accepted. Once you set an explicit media type, that media type in the requests' Content-Type header will be validated on incoming requests, but this behavior can be disabled via the enforce_media_type parameter to File() .","title":"File Uploads"},{"location":"tutorial/files/#files","text":"You can read the request body directly into a file or bytes. This will read the data from the top level request body, and can only support 1 file. To receive multiple files, see the multipart/form-data documentation . from xpresso import App , FromFile , Path , UploadFile async def count_bytes_in_file ( file : FromFile [ UploadFile ]) -> int : return len ( await file . read ()) app = App ( routes = [ Path ( path = \"/count-bytes\" , put = count_bytes_in_file )]) Note UploadFile is a class provided by Starlette that buffers the data in memory and overflows to disk if the data is larger than a predefined threshold. This prevents a large file from exhausting your hardware's memory, but does use disk space and CPU cycles for buffering. Implementation detail xpresso.UploadFile is just a thin wrapper around starlette.datastructures.UploadFile , but you must use xpresso.UploadFile instead of starlette.datastructures.UploadFile directly, otherwise Xpresso won't know how to build the argument.","title":"Files"},{"location":"tutorial/files/#as-bytes","text":"Xpresso can read the entire file into memory if you'd like: from xpresso import App , FromFile , Path async def count_bytes_in_file ( data : FromFile [ bytes ]) -> int : return len ( data ) app = App ( routes = [ Path ( path = \"/count-bytes\" , put = count_bytes_in_file )]) This can be convenient if you know the files are not large.","title":"As bytes"},{"location":"tutorial/files/#as-a-stream","text":"If you want to read the bytes without buffering to disk or memory, use xpresso.BinaryStream as the type: from xpresso import App , BinaryStream , FromFile , Path async def count_bytes_in_file ( data : FromFile [ BinaryStream ]) -> int : size = 0 async for chunk in data : size += len ( chunk ) return size app = App ( routes = [ Path ( path = \"/count-bytes\" , put = count_bytes_in_file )]) Implementation detail xpresso.BinaryStream is just a thin wrapper around typing.AsyncIterator[bytes] , but you must use xpresso.BinaryStream instead of typing.AsyncIterator[bytes] directly, otherwise Xpresso won't know how to build the argument.","title":"As a stream"},{"location":"tutorial/files/#setting-the-expected-content-type","text":"You can set the media type via the media_type parameter to File() and enforce it via the enforce_media_type parameter: from xpresso import App , File , Path , UploadFile from xpresso.typing import Annotated async def count_image_bytes ( file : Annotated [ UploadFile , File ( media_type = \"image/*\" , enforce_media_type = True ), ] ) -> int : return len ( await file . read ()) app = App ( routes = [ Path ( path = \"/count-bytes\" , put = count_image_bytes )]) Media types can be a media type (e.g. image/png ) or a media type range (e.g. image/* ). If you do not explicitly set the media type, all media types are accepted. Once you set an explicit media type, that media type in the requests' Content-Type header will be validated on incoming requests, but this behavior can be disabled via the enforce_media_type parameter to File() .","title":"Setting the expected content-type"},{"location":"tutorial/forms/","text":"Forms To extract forms in Xpresso, you start by declaring a data structure to unpack the form into. The fields of the datastructure correspond to the fields of the form data. The datastructure can be almost anything, including dataclasses, pydantic models and regular Python classes. from dataclasses import dataclass from typing import List from pydantic import BaseModel from xpresso import ( App , ExtractField , FromFormData , FromFormField , FromJson , Path , ) class JsonModel ( BaseModel ): foo : str @dataclass ( frozen = True ) class FormDataModel : name : str # implicit FromFormField[str] tags : FromFormField [ List [ str ]] json_data : ExtractField [ FromJson [ JsonModel ]] async def compare_json_to_form ( form : FromFormData [ FormDataModel ], ) -> bool : return form . json_data . foo in form . tags app = App ( routes = [ Path ( path = \"/form\" , post = compare_json_to_form )]) This request extracts a application/x-www-form-urlencoded request into a FormDataModel object. Note Form fields ( FromFormField ) are extracted from the form directly, but things like JSON or files need to be yanked out of a specific field before they are parsed/extracted. So for non form-native fields (anything except FromFormField ) you need to wrap it in ExtractField . Form serialization Xpresso fully supports the OpenAPI parameter serialization standard. You can customize how extraction ocurrs using the style and explode keyword arguments to FormField() : from dataclasses import dataclass from typing import List from xpresso import App , FormEncodedField , FromFormData , Path from xpresso.typing import Annotated @dataclass ( frozen = True ) class FormDataModel : tags : Annotated [ List [ str ], FormEncodedField ( style = \"spaceDelimited\" , explode = False ), ] async def echo_tags ( form : FromFormData [ FormDataModel ]) -> List [ str ]: return form . tags # returned as JSON app = App ( routes = [ Path ( path = \"/echo-tags\" , post = echo_tags )]) Multipart requests Multipart requests ( multipart/form-data ) can be parsed almost identically to application/x-www-form-urlencoded . You can't upload mixed files and data in an application/x-www-form-urlencoded request, so you'll need to use a Multipart request. Multipart requests even support multiple files: from dataclasses import dataclass from typing import List from pydantic import BaseModel from xpresso import ( App , ExtractRepeatedField , FromFile , FromFormField , FromMultipart , Path , UploadFile , ) class JsonModel ( BaseModel ): foo : str @dataclass ( frozen = True ) class FormDataModel : name : str # implicit FromFormField[str] tags : FromFormField [ List [ str ]] files : ExtractRepeatedField [ FromFile [ List [ UploadFile ]]] class UserUploadMetadata ( BaseModel ): name : str tags : List [ str ] nbytes : int async def upload_data ( form : FromMultipart [ FormDataModel ], ) -> UserUploadMetadata : nbytes = 0 for file in form . files : nbytes += len ( await file . read ()) return UserUploadMetadata ( name = form . name , tags = form . tags , nbytes = nbytes , ) app = App ( routes = [ Path ( path = \"/form\" , post = upload_data )]) Note Fields in a application/x-www-form-urlencoded or multipart/form-data request can be repeated. This just means that a field of the same name appears more than once in the request. Often this is used to upload multiple files, such as in the example above. To declare repeated fields we need to do two things: 1. Use ExtractRepeatedField instead of ExtractField . 1. Make sure our type is actually a List/Tuple/Set (any sequence will do).","title":"Forms"},{"location":"tutorial/forms/#forms","text":"To extract forms in Xpresso, you start by declaring a data structure to unpack the form into. The fields of the datastructure correspond to the fields of the form data. The datastructure can be almost anything, including dataclasses, pydantic models and regular Python classes. from dataclasses import dataclass from typing import List from pydantic import BaseModel from xpresso import ( App , ExtractField , FromFormData , FromFormField , FromJson , Path , ) class JsonModel ( BaseModel ): foo : str @dataclass ( frozen = True ) class FormDataModel : name : str # implicit FromFormField[str] tags : FromFormField [ List [ str ]] json_data : ExtractField [ FromJson [ JsonModel ]] async def compare_json_to_form ( form : FromFormData [ FormDataModel ], ) -> bool : return form . json_data . foo in form . tags app = App ( routes = [ Path ( path = \"/form\" , post = compare_json_to_form )]) This request extracts a application/x-www-form-urlencoded request into a FormDataModel object. Note Form fields ( FromFormField ) are extracted from the form directly, but things like JSON or files need to be yanked out of a specific field before they are parsed/extracted. So for non form-native fields (anything except FromFormField ) you need to wrap it in ExtractField .","title":"Forms"},{"location":"tutorial/forms/#form-serialization","text":"Xpresso fully supports the OpenAPI parameter serialization standard. You can customize how extraction ocurrs using the style and explode keyword arguments to FormField() : from dataclasses import dataclass from typing import List from xpresso import App , FormEncodedField , FromFormData , Path from xpresso.typing import Annotated @dataclass ( frozen = True ) class FormDataModel : tags : Annotated [ List [ str ], FormEncodedField ( style = \"spaceDelimited\" , explode = False ), ] async def echo_tags ( form : FromFormData [ FormDataModel ]) -> List [ str ]: return form . tags # returned as JSON app = App ( routes = [ Path ( path = \"/echo-tags\" , post = echo_tags )])","title":"Form serialization"},{"location":"tutorial/forms/#multipart-requests","text":"Multipart requests ( multipart/form-data ) can be parsed almost identically to application/x-www-form-urlencoded . You can't upload mixed files and data in an application/x-www-form-urlencoded request, so you'll need to use a Multipart request. Multipart requests even support multiple files: from dataclasses import dataclass from typing import List from pydantic import BaseModel from xpresso import ( App , ExtractRepeatedField , FromFile , FromFormField , FromMultipart , Path , UploadFile , ) class JsonModel ( BaseModel ): foo : str @dataclass ( frozen = True ) class FormDataModel : name : str # implicit FromFormField[str] tags : FromFormField [ List [ str ]] files : ExtractRepeatedField [ FromFile [ List [ UploadFile ]]] class UserUploadMetadata ( BaseModel ): name : str tags : List [ str ] nbytes : int async def upload_data ( form : FromMultipart [ FormDataModel ], ) -> UserUploadMetadata : nbytes = 0 for file in form . files : nbytes += len ( await file . read ()) return UserUploadMetadata ( name = form . name , tags = form . tags , nbytes = nbytes , ) app = App ( routes = [ Path ( path = \"/form\" , post = upload_data )]) Note Fields in a application/x-www-form-urlencoded or multipart/form-data request can be repeated. This just means that a field of the same name appears more than once in the request. Often this is used to upload multiple files, such as in the example above. To declare repeated fields we need to do two things: 1. Use ExtractRepeatedField instead of ExtractField . 1. Make sure our type is actually a List/Tuple/Set (any sequence will do).","title":"Multipart requests"},{"location":"tutorial/header_params/","text":"Header Parameters Header parameters are declared the same way as Query and Path parameters: from typing import Dict , Optional from xpresso import App , FromHeader , Path async def read_items ( accept_language : FromHeader [ Optional [ str ]] = None , ) -> Dict [ str , Optional [ str ]]: return { \"Accept-Language\" : accept_language } app = App ( routes = [ Path ( \"/items/\" , get = read_items , ) ] ) Underscore conversion Headers names are usually composed of several words separated by hyphens ( \"-\" ). But Python veriable names cannot contain hyphens. Since Xpresso automatically derives the header names from the parameter names, this creates a problem. To get around this, Xpresso automatically converts parameter name underscores ( \"_\" ) to hyphens ( \"-\" ). This is controlled using the convert_underscores parameter to HeaderParam(...) : from typing import Dict , Optional from xpresso import App , HeaderParam , Path from xpresso.typing import Annotated async def read_items ( some_header : Annotated [ str , HeaderParam ( convert_underscores = False ) ] ) -> Dict [ str , Optional [ str ]]: return { \"some_header\" : some_header } app = App ( routes = [ Path ( \"/items/\" , get = read_items , ) ] ) Tip The import from Xpresso.typing import Annotated is just a convenience import. All it does is import Annotated from typing if your Python version is >= 3.9 and [typing_extensions] otherwise. But if you are already using Python >= 3.9, you can just replace that with from typing import Annotated . Warning It is pretty uncommon to use headers with underscores. You should probably think twice about setting convert_underscores=False and test that it doesn't break your clients, proxies, etc. Repeated Headers Serialization and Parsing","title":"Header Parameters"},{"location":"tutorial/header_params/#header-parameters","text":"Header parameters are declared the same way as Query and Path parameters: from typing import Dict , Optional from xpresso import App , FromHeader , Path async def read_items ( accept_language : FromHeader [ Optional [ str ]] = None , ) -> Dict [ str , Optional [ str ]]: return { \"Accept-Language\" : accept_language } app = App ( routes = [ Path ( \"/items/\" , get = read_items , ) ] )","title":"Header Parameters"},{"location":"tutorial/header_params/#underscore-conversion","text":"Headers names are usually composed of several words separated by hyphens ( \"-\" ). But Python veriable names cannot contain hyphens. Since Xpresso automatically derives the header names from the parameter names, this creates a problem. To get around this, Xpresso automatically converts parameter name underscores ( \"_\" ) to hyphens ( \"-\" ). This is controlled using the convert_underscores parameter to HeaderParam(...) : from typing import Dict , Optional from xpresso import App , HeaderParam , Path from xpresso.typing import Annotated async def read_items ( some_header : Annotated [ str , HeaderParam ( convert_underscores = False ) ] ) -> Dict [ str , Optional [ str ]]: return { \"some_header\" : some_header } app = App ( routes = [ Path ( \"/items/\" , get = read_items , ) ] ) Tip The import from Xpresso.typing import Annotated is just a convenience import. All it does is import Annotated from typing if your Python version is >= 3.9 and [typing_extensions] otherwise. But if you are already using Python >= 3.9, you can just replace that with from typing import Annotated . Warning It is pretty uncommon to use headers with underscores. You should probably think twice about setting convert_underscores=False and test that it doesn't break your clients, proxies, etc.","title":"Underscore conversion"},{"location":"tutorial/header_params/#repeated-headers","text":"","title":"Repeated Headers"},{"location":"tutorial/header_params/#serialization-and-parsing","text":"","title":"Serialization and Parsing"},{"location":"tutorial/lifespan/","text":"Lifespans Xpresso supports lifespan context managers from Starlette . This is the only way to handle startup/shutdown; there are no startup/shutdown events in Xpresso. The main difference vs. Starlette is that the lifespan context manager is allowed to depend on \"app\" scoped dependencies (see Dependency Scopes ), including the App itself: from contextlib import asynccontextmanager from typing import AsyncIterator from pydantic import BaseModel from xpresso import App , Path class AppState ( BaseModel ): started : bool = False @asynccontextmanager async def lifespan ( state : AppState ) -> AsyncIterator [ None ]: state . started = True yield class AppHealth ( BaseModel ): running : bool async def healthcheck ( state : AppState ) -> AppHealth : return AppHealth ( running = state . started ) app = App ( lifespan = lifespan , routes = [ Path ( \"/health\" , get = healthcheck )] ) Tip You don't need app.state or request.state in Xpresso. Instead, you can create you own strongly typed mutable or immutable state object and inject it into your lifespan and/or endpoints like in the example above. Router lifespans Routers can also have lifespans, and these lifespans will be executed when the top level App 's lifespan executes: from contextlib import asynccontextmanager from typing import AsyncIterator , List from xpresso import App , Path , Router from xpresso.routing.mount import Mount class Logger ( List [ str ]): pass @asynccontextmanager async def app_lifespan ( logger : Logger ) -> AsyncIterator [ None ]: logger . append ( \"App lifespan\" ) yield @asynccontextmanager async def router_lifespan ( logger : Logger ) -> AsyncIterator [ None ]: logger . append ( \"Router lifespan\" ) yield async def get_logs ( logger : Logger ) -> List [ str ]: return logger app = App ( routes = [ Mount ( \"\" , app = Router ( routes = [ Path ( \"/logs\" , get = get_logs , ) ], lifespan = router_lifespan , ), ) ], lifespan = app_lifespan , ) Note Only Xpresso Routers and mounted Apps support multiple lifespans. Lifespans for arbitrary mounted ASGI apps (using Mount ) will not work.","title":"Lifespans"},{"location":"tutorial/lifespan/#lifespans","text":"Xpresso supports lifespan context managers from Starlette . This is the only way to handle startup/shutdown; there are no startup/shutdown events in Xpresso. The main difference vs. Starlette is that the lifespan context manager is allowed to depend on \"app\" scoped dependencies (see Dependency Scopes ), including the App itself: from contextlib import asynccontextmanager from typing import AsyncIterator from pydantic import BaseModel from xpresso import App , Path class AppState ( BaseModel ): started : bool = False @asynccontextmanager async def lifespan ( state : AppState ) -> AsyncIterator [ None ]: state . started = True yield class AppHealth ( BaseModel ): running : bool async def healthcheck ( state : AppState ) -> AppHealth : return AppHealth ( running = state . started ) app = App ( lifespan = lifespan , routes = [ Path ( \"/health\" , get = healthcheck )] ) Tip You don't need app.state or request.state in Xpresso. Instead, you can create you own strongly typed mutable or immutable state object and inject it into your lifespan and/or endpoints like in the example above.","title":"Lifespans"},{"location":"tutorial/lifespan/#router-lifespans","text":"Routers can also have lifespans, and these lifespans will be executed when the top level App 's lifespan executes: from contextlib import asynccontextmanager from typing import AsyncIterator , List from xpresso import App , Path , Router from xpresso.routing.mount import Mount class Logger ( List [ str ]): pass @asynccontextmanager async def app_lifespan ( logger : Logger ) -> AsyncIterator [ None ]: logger . append ( \"App lifespan\" ) yield @asynccontextmanager async def router_lifespan ( logger : Logger ) -> AsyncIterator [ None ]: logger . append ( \"Router lifespan\" ) yield async def get_logs ( logger : Logger ) -> List [ str ]: return logger app = App ( routes = [ Mount ( \"\" , app = Router ( routes = [ Path ( \"/logs\" , get = get_logs , ) ], lifespan = router_lifespan , ), ) ], lifespan = app_lifespan , ) Note Only Xpresso Routers and mounted Apps support multiple lifespans. Lifespans for arbitrary mounted ASGI apps (using Mount ) will not work.","title":"Router lifespans"},{"location":"tutorial/minimal_app/","text":"Getting started: a minimal Xpresso app Start by making a file called main.py and fill out the following code: from xpresso import App , Path async def endpoint (): return { \"message\" : \"Hello World\" } app = App ( routes = [ Path ( path = \"/\" , get = endpoint )]) What we've done here so far is: Create an endpoint function. Create a PathItem. A PathItem represents a unique HTTP resource, and can have several http methods attached to it. Bind our endpoint function to the PathItem's GET method. Create an App instance that uses the PathItem. This is actually all we need, so you can run this using Uvicorn: uvicorn main : app Now navigate to http://localhost:8000/ and you should see {\"message\": \"Hello World\"} on your screen. Interactive Swagger Docs You can also navigate to http://localhost:8000/docs to see the OpenAPI docs, served via Swagger UI . Info Swagger UI is a collection of HTML and scripts that serve as a frontend to an OpenAPI specification. Swagger gives you an interactive UI where you can send requests and get responses from your backend, all based on the OpenAPI specification that Xpresso automatically builds for you. Since we didn't give Xpresso much info on the endpoint function's return value (it is implicitly None ) and there is no request body, there isn't much information in OpenAPI. In later chapters, you will see how we can give Xpresso more information.","title":"Minimal App"},{"location":"tutorial/minimal_app/#getting-started-a-minimal-xpresso-app","text":"Start by making a file called main.py and fill out the following code: from xpresso import App , Path async def endpoint (): return { \"message\" : \"Hello World\" } app = App ( routes = [ Path ( path = \"/\" , get = endpoint )]) What we've done here so far is: Create an endpoint function. Create a PathItem. A PathItem represents a unique HTTP resource, and can have several http methods attached to it. Bind our endpoint function to the PathItem's GET method. Create an App instance that uses the PathItem. This is actually all we need, so you can run this using Uvicorn: uvicorn main : app Now navigate to http://localhost:8000/ and you should see {\"message\": \"Hello World\"} on your screen.","title":"Getting started: a minimal Xpresso app"},{"location":"tutorial/minimal_app/#interactive-swagger-docs","text":"You can also navigate to http://localhost:8000/docs to see the OpenAPI docs, served via Swagger UI . Info Swagger UI is a collection of HTML and scripts that serve as a frontend to an OpenAPI specification. Swagger gives you an interactive UI where you can send requests and get responses from your backend, all based on the OpenAPI specification that Xpresso automatically builds for you. Since we didn't give Xpresso much info on the endpoint function's return value (it is implicitly None ) and there is no request body, there isn't much information in OpenAPI. In later chapters, you will see how we can give Xpresso more information.","title":"Interactive Swagger Docs"},{"location":"tutorial/param_constraints_and_metadata/","text":"Constraints and Metadata for Parameters Constraints and validation Query, Path, Header and Cookie parameters benefit from Pydantic's rich validation and schema generation. You can attach extra validation and schema metadata using Pydantic's Field() . For in depth information on the topic, see Pydantic 's docs. But here is a quick example of how this can work in Xpresso. First, import Field from Pydantic and Annotated from typing (Python >= 3.9), typing_extensions (Python <= 3.9) or xpresso.typing (any Python version): from pydantic import Field from xpresso import App , Path , QueryParam from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_item ( skip : Annotated [ int , QueryParam ( description = \"Count of items to skip starting from the 0th item\" ), Field ( gt = 0 ), ], limit : Annotated [ int , QueryParam (), Field ( gt = 0 , description = \"Maximum number of items to return\" ), ], ): return fake_items_db [ skip : skip + limit ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Tip The import from Xpresso.typing import Annotated is just a convenience import. All it does is import Annotated from typing if your Python version is >= 3.9 and [typing_extensions] otherwise. But if you are already using Python >= 3.9, you can just replace that with from typing import Annotated . Now use Field() inside of Annotated[...] to attach validation and schema customization metadata to the price field: from pydantic import Field from xpresso import App , Path , QueryParam from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_item ( skip : Annotated [ int , QueryParam ( description = \"Count of items to skip starting from the 0th item\" ), Field ( gt = 0 ), ], limit : Annotated [ int , QueryParam (), Field ( gt = 0 , description = \"Maximum number of items to return\" ), ], ): return fake_items_db [ skip : skip + limit ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Note You'll notice that there is some overlap between the parameters to QueryParam(...) and Field(...) , for example description . This is just a convenience for you, the developer, so that you don't have to import Field(...) for the most common use cases. Whenever there is a duplicate parameter, the value in QueryParam(...) is preferred with a fallback to Field(...) 's value. Tip If you are adding a lot of metadata, it may be convenient to make a [PEP 613 type alias] at the module level. For example, you can do Limit = Annotated[int, QueryParam(), Field(gt=0)] and then use that like limit: Limit in your endpoint function. This is also useful if you are re-using the same parameter in multiple function signatures or even across modules. Of course, you will get automatic validation of the gt constraints and the metadata will be reflected in the OpenAPI schema: Pydantic's types Pydantic provides a set of types like HttpUrl and constr (constrained string). You can use these as the types for parameters and they will be validated and parsed correctly. For more information, see Pydantic's docs on the matter . Deprecated parameters All parameter markers ( PathParam(...) , QueryParam(...) , ...) support a deprecated argument. This can be used to mark a parameter as deprecated in OpenAPI. Examples All parameter markers ( PathParam(...) , QueryParam(...) , ...) support a examples argument to add examples to the OpenAPI docs. First, we'll declare our examples. Examples are a dictionary with example names as keys and Example objects as values. Each Example object requires a value , but can also have a description, summary and other metadata. import re from typing import List from xpresso import App , Path , QueryParam from xpresso.openapi.models import Example from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] prefix_examples = { \"Starts with Foo\" : Example ( value = \"Foo.*\" ), \"Starts with Foo or Bar\" : Example ( value = \"Foo.*|Bar.*\" ), } QueryFilter = Annotated [ str , QueryParam ( description = \"Regular expression to filter items by name\" , examples = prefix_examples , ), ] async def read_item ( filter : QueryFilter ) -> List [ str ]: return [ item [ \"item_name\" ] for item in fake_items_db if re . match ( filter , item [ \"item_name\" ]) ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Then we can make an alias for our type declaration to avoid clutter in our endpoint function and enable re-use: import re from typing import List from xpresso import App , Path , QueryParam from xpresso.openapi.models import Example from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] prefix_examples = { \"Starts with Foo\" : Example ( value = \"Foo.*\" ), \"Starts with Foo or Bar\" : Example ( value = \"Foo.*|Bar.*\" ), } QueryFilter = Annotated [ str , QueryParam ( description = \"Regular expression to filter items by name\" , examples = prefix_examples , ), ] async def read_item ( filter : QueryFilter ) -> List [ str ]: return [ item [ \"item_name\" ] for item in fake_items_db if re . match ( filter , item [ \"item_name\" ]) ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Finally we use this type alias in our endpoint function signature: import re from typing import List from xpresso import App , Path , QueryParam from xpresso.openapi.models import Example from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] prefix_examples = { \"Starts with Foo\" : Example ( value = \"Foo.*\" ), \"Starts with Foo or Bar\" : Example ( value = \"Foo.*|Bar.*\" ), } QueryFilter = Annotated [ str , QueryParam ( description = \"Regular expression to filter items by name\" , examples = prefix_examples , ), ] async def read_item ( filter : QueryFilter ) -> List [ str ]: return [ item [ \"item_name\" ] for item in fake_items_db if re . match ( filter , item [ \"item_name\" ]) ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Our OpenAPI docs will now include the examples:","title":"Parameter Constraints and Metadata"},{"location":"tutorial/param_constraints_and_metadata/#constraints-and-metadata-for-parameters","text":"","title":"Constraints and Metadata for Parameters"},{"location":"tutorial/param_constraints_and_metadata/#constraints-and-validation","text":"Query, Path, Header and Cookie parameters benefit from Pydantic's rich validation and schema generation. You can attach extra validation and schema metadata using Pydantic's Field() . For in depth information on the topic, see Pydantic 's docs. But here is a quick example of how this can work in Xpresso. First, import Field from Pydantic and Annotated from typing (Python >= 3.9), typing_extensions (Python <= 3.9) or xpresso.typing (any Python version): from pydantic import Field from xpresso import App , Path , QueryParam from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_item ( skip : Annotated [ int , QueryParam ( description = \"Count of items to skip starting from the 0th item\" ), Field ( gt = 0 ), ], limit : Annotated [ int , QueryParam (), Field ( gt = 0 , description = \"Maximum number of items to return\" ), ], ): return fake_items_db [ skip : skip + limit ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Tip The import from Xpresso.typing import Annotated is just a convenience import. All it does is import Annotated from typing if your Python version is >= 3.9 and [typing_extensions] otherwise. But if you are already using Python >= 3.9, you can just replace that with from typing import Annotated . Now use Field() inside of Annotated[...] to attach validation and schema customization metadata to the price field: from pydantic import Field from xpresso import App , Path , QueryParam from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_item ( skip : Annotated [ int , QueryParam ( description = \"Count of items to skip starting from the 0th item\" ), Field ( gt = 0 ), ], limit : Annotated [ int , QueryParam (), Field ( gt = 0 , description = \"Maximum number of items to return\" ), ], ): return fake_items_db [ skip : skip + limit ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Note You'll notice that there is some overlap between the parameters to QueryParam(...) and Field(...) , for example description . This is just a convenience for you, the developer, so that you don't have to import Field(...) for the most common use cases. Whenever there is a duplicate parameter, the value in QueryParam(...) is preferred with a fallback to Field(...) 's value. Tip If you are adding a lot of metadata, it may be convenient to make a [PEP 613 type alias] at the module level. For example, you can do Limit = Annotated[int, QueryParam(), Field(gt=0)] and then use that like limit: Limit in your endpoint function. This is also useful if you are re-using the same parameter in multiple function signatures or even across modules. Of course, you will get automatic validation of the gt constraints and the metadata will be reflected in the OpenAPI schema:","title":"Constraints and validation"},{"location":"tutorial/param_constraints_and_metadata/#pydantics-types","text":"Pydantic provides a set of types like HttpUrl and constr (constrained string). You can use these as the types for parameters and they will be validated and parsed correctly. For more information, see Pydantic's docs on the matter .","title":"Pydantic's types"},{"location":"tutorial/param_constraints_and_metadata/#deprecated-parameters","text":"All parameter markers ( PathParam(...) , QueryParam(...) , ...) support a deprecated argument. This can be used to mark a parameter as deprecated in OpenAPI.","title":"Deprecated parameters"},{"location":"tutorial/param_constraints_and_metadata/#examples","text":"All parameter markers ( PathParam(...) , QueryParam(...) , ...) support a examples argument to add examples to the OpenAPI docs. First, we'll declare our examples. Examples are a dictionary with example names as keys and Example objects as values. Each Example object requires a value , but can also have a description, summary and other metadata. import re from typing import List from xpresso import App , Path , QueryParam from xpresso.openapi.models import Example from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] prefix_examples = { \"Starts with Foo\" : Example ( value = \"Foo.*\" ), \"Starts with Foo or Bar\" : Example ( value = \"Foo.*|Bar.*\" ), } QueryFilter = Annotated [ str , QueryParam ( description = \"Regular expression to filter items by name\" , examples = prefix_examples , ), ] async def read_item ( filter : QueryFilter ) -> List [ str ]: return [ item [ \"item_name\" ] for item in fake_items_db if re . match ( filter , item [ \"item_name\" ]) ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Then we can make an alias for our type declaration to avoid clutter in our endpoint function and enable re-use: import re from typing import List from xpresso import App , Path , QueryParam from xpresso.openapi.models import Example from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] prefix_examples = { \"Starts with Foo\" : Example ( value = \"Foo.*\" ), \"Starts with Foo or Bar\" : Example ( value = \"Foo.*|Bar.*\" ), } QueryFilter = Annotated [ str , QueryParam ( description = \"Regular expression to filter items by name\" , examples = prefix_examples , ), ] async def read_item ( filter : QueryFilter ) -> List [ str ]: return [ item [ \"item_name\" ] for item in fake_items_db if re . match ( filter , item [ \"item_name\" ]) ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Finally we use this type alias in our endpoint function signature: import re from typing import List from xpresso import App , Path , QueryParam from xpresso.openapi.models import Example from xpresso.typing import Annotated fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] prefix_examples = { \"Starts with Foo\" : Example ( value = \"Foo.*\" ), \"Starts with Foo or Bar\" : Example ( value = \"Foo.*|Bar.*\" ), } QueryFilter = Annotated [ str , QueryParam ( description = \"Regular expression to filter items by name\" , examples = prefix_examples , ), ] async def read_item ( filter : QueryFilter ) -> List [ str ]: return [ item [ \"item_name\" ] for item in fake_items_db if re . match ( filter , item [ \"item_name\" ]) ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Our OpenAPI docs will now include the examples:","title":"Examples"},{"location":"tutorial/path_params/","text":"Path parameters Path parameters are declared in the route definition, using the same format as formatting strings ( \"{}\" ): To tell Xpresso that you want to extract a path parameter and inject it into your function, use FromPath . This is just a marker that tells Xpresso how to inject the value, it has no effect on the function if it is called directly. from typing import Dict from xpresso import App , FromPath , Path async def read_item ( item_id : FromPath [ str ]) -> Dict [ str , str ]: return { \"item_id\" : item_id } app = App ( routes = [ Path ( path = \"/items/ {item_id} \" , get = read_item , ), ] ) If you run this example using Uvicorn, you can go to http://127.0.0.1:8000/items/1234 ( 1234 is an arbitrary string) and you'll get a JSON response in your browser like: { \"item_id\" : \"1234\" } Type conversions Xpresso uses type annotations from your parameters to do conversions and parsing. If we modify the example above to expect an int , Xpresso will convert the path parameter (which is always a string, since it is coming from a URL) into an int and automatically return an error response if it is not a valid integer: from typing import Dict from xpresso import App , FromPath , Path async def read_item ( item_id : FromPath [ int ]) -> Dict [ str , int ]: return { \"item_id\" : item_id } app = App ( routes = [ Path ( path = \"/items/ {item_id} \" , get = read_item , ), ] ) Now if you navigate to http://127.0.0.1:8000/items/1234 (the same URL as before) you will get back a response with an integer instead of a string: { \"item_id\" : 1234 } Let's try passing in something that is not an integer. Navigate to http://127.0.0.1:8000/items/foobarbaz and you'll get back: { \"detail\" : [ { \"loc\" : [ \"path\" , \"item_id\" ], \"msg\" : \"value is not a valid integer\" , \"type\" : \"type_error.integer\" } ] } Under the hood, we use Pydantic for this parsing and validation. So you can also use Pydantic constraints: from typing import Dict from pydantic import Field from xpresso import App , Path , PathParam from xpresso.typing import Annotated async def read_item ( item_id : Annotated [ int , PathParam (), Field ( gt = 0 )] ) -> Dict [ str , int ]: return { \"item_id\" : item_id } app = App ( routes = [ Path ( path = \"/items/ {item_id} \" , get = read_item , ), ] ) Info This is probably a good spot to digress and talk about Annotated since you may be confused if you are not familiar with it. If you've used FastAPI, you may be used to declaring things like param: str = Path(gt=0) . In Xpresso, this turns into param: Annotated[str, Path(), Field(gt=0)] . For more background on Annotated itself, see the Python Types section of our docs. Tip The import from Xpresso.typing import Annotated is just a convenience import. All it does is import Annotated from typing if your Python version is >= 3.9 and typing_extensions otherwise. But if you are already using Python >= 3.9, you can just replace that with from typing import Annotated . Navigating to http://127.0.0.1:8000/items/1 (a positive value) will give you: { \"item_id\" : 1 } But if you try http://127.0.0.1:8000/items/-1 (a negative value): { \"detail\" : [ { \"ctx\" : { \"limit_value\" : 0 }, \"loc\" : [ \"path\" , \"item_id\" ], \"msg\" : \"ensure this value is greater than 0\" , \"type\" : \"value_error.number.not_gt\" } ] } OpenAPI documentation If you run one of the examples above and navigate to http://127.0.0.1:8000/docs you'll see the OpenAPI documentation. It should look something like: Array path parameters Xpresso offers full support for the the OpenAPI parameter serialization spec . You can control the serialization style using the style and explode arguments to PathParam() : The Python type can be a scalar value, a collection (like a list or dict) or even a Pydantic model (for object-valued parameters). from typing import List from xpresso import App , Path , PathParam from xpresso.typing import Annotated async def read_items ( items : Annotated [ List [ int ], PathParam ( explode = True , style = \"matrix\" ) ] ) -> List [ int ]: return items app = App ( routes = [ Path ( path = \"/items/ {items} \" , get = read_items , ), ] ) Navigating to http://127.0.0.1:8000/items/;items=1;items=2;items=3 will return the following JSON: [ 1 , 2 , 3 ]","title":"Path Parameters"},{"location":"tutorial/path_params/#path-parameters","text":"Path parameters are declared in the route definition, using the same format as formatting strings ( \"{}\" ): To tell Xpresso that you want to extract a path parameter and inject it into your function, use FromPath . This is just a marker that tells Xpresso how to inject the value, it has no effect on the function if it is called directly. from typing import Dict from xpresso import App , FromPath , Path async def read_item ( item_id : FromPath [ str ]) -> Dict [ str , str ]: return { \"item_id\" : item_id } app = App ( routes = [ Path ( path = \"/items/ {item_id} \" , get = read_item , ), ] ) If you run this example using Uvicorn, you can go to http://127.0.0.1:8000/items/1234 ( 1234 is an arbitrary string) and you'll get a JSON response in your browser like: { \"item_id\" : \"1234\" }","title":"Path parameters"},{"location":"tutorial/path_params/#type-conversions","text":"Xpresso uses type annotations from your parameters to do conversions and parsing. If we modify the example above to expect an int , Xpresso will convert the path parameter (which is always a string, since it is coming from a URL) into an int and automatically return an error response if it is not a valid integer: from typing import Dict from xpresso import App , FromPath , Path async def read_item ( item_id : FromPath [ int ]) -> Dict [ str , int ]: return { \"item_id\" : item_id } app = App ( routes = [ Path ( path = \"/items/ {item_id} \" , get = read_item , ), ] ) Now if you navigate to http://127.0.0.1:8000/items/1234 (the same URL as before) you will get back a response with an integer instead of a string: { \"item_id\" : 1234 } Let's try passing in something that is not an integer. Navigate to http://127.0.0.1:8000/items/foobarbaz and you'll get back: { \"detail\" : [ { \"loc\" : [ \"path\" , \"item_id\" ], \"msg\" : \"value is not a valid integer\" , \"type\" : \"type_error.integer\" } ] } Under the hood, we use Pydantic for this parsing and validation. So you can also use Pydantic constraints: from typing import Dict from pydantic import Field from xpresso import App , Path , PathParam from xpresso.typing import Annotated async def read_item ( item_id : Annotated [ int , PathParam (), Field ( gt = 0 )] ) -> Dict [ str , int ]: return { \"item_id\" : item_id } app = App ( routes = [ Path ( path = \"/items/ {item_id} \" , get = read_item , ), ] ) Info This is probably a good spot to digress and talk about Annotated since you may be confused if you are not familiar with it. If you've used FastAPI, you may be used to declaring things like param: str = Path(gt=0) . In Xpresso, this turns into param: Annotated[str, Path(), Field(gt=0)] . For more background on Annotated itself, see the Python Types section of our docs. Tip The import from Xpresso.typing import Annotated is just a convenience import. All it does is import Annotated from typing if your Python version is >= 3.9 and typing_extensions otherwise. But if you are already using Python >= 3.9, you can just replace that with from typing import Annotated . Navigating to http://127.0.0.1:8000/items/1 (a positive value) will give you: { \"item_id\" : 1 } But if you try http://127.0.0.1:8000/items/-1 (a negative value): { \"detail\" : [ { \"ctx\" : { \"limit_value\" : 0 }, \"loc\" : [ \"path\" , \"item_id\" ], \"msg\" : \"ensure this value is greater than 0\" , \"type\" : \"value_error.number.not_gt\" } ] }","title":"Type conversions"},{"location":"tutorial/path_params/#openapi-documentation","text":"If you run one of the examples above and navigate to http://127.0.0.1:8000/docs you'll see the OpenAPI documentation. It should look something like:","title":"OpenAPI documentation"},{"location":"tutorial/path_params/#array-path-parameters","text":"Xpresso offers full support for the the OpenAPI parameter serialization spec . You can control the serialization style using the style and explode arguments to PathParam() : The Python type can be a scalar value, a collection (like a list or dict) or even a Pydantic model (for object-valued parameters). from typing import List from xpresso import App , Path , PathParam from xpresso.typing import Annotated async def read_items ( items : Annotated [ List [ int ], PathParam ( explode = True , style = \"matrix\" ) ] ) -> List [ int ]: return items app = App ( routes = [ Path ( path = \"/items/ {items} \" , get = read_items , ), ] ) Navigating to http://127.0.0.1:8000/items/;items=1;items=2;items=3 will return the following JSON: [ 1 , 2 , 3 ]","title":"Array path parameters"},{"location":"tutorial/query_params/","text":"Query parameters Query parameters are the named parameters that come after the ? in a URL: http://example.com/some/paths/?skip=1&limit=2 This URL has two simple query parameters: skip : value of 1 limit : value of 2 In Xpresso, these are extracted using FromQuery[...] , which is an alias for Annoated[..., QueryParam()] . Since they are part of the URL, they are always received as strings. But just like with path parameters, Xpresso can extract them and parse them into Python types and data structrues: from xpresso import App , FromQuery , Path fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_items ( skip : FromQuery [ int ] = 0 , limit : FromQuery [ int ] = 2 ): return fake_items_db [ skip : skip + limit ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_items , ), ] ) Now navigate to http://127.0.0.1:8000/items/?skip=1&limit=1 to see the query parameters being used to filter items. You should get the following response: [ { \"item_name\" : \"Bar\" } ] Default (optional) parameters Unlike path parameters which are always required, query paramters can be optional. To make a query parameter optional, simply give the parameter a default value like we do for limit and skip . So, for our example above http://localhost:8000/items/?skip=0&limit=2 and http://localhost:8000/items/ will produce the same result: [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" } ] Of course if you don't give the parameter a default value, it will be required and an error response will automatically be returned if it is missing. For example, given: from typing import Dict from xpresso import App , FromQuery , Path async def double ( input : FromQuery [ int ]) -> Dict [ str , int ]: return { \"result\" : input * 2 } app = App ( routes = [ Path ( path = \"/math/double\" , get = double , ), ] ) If you navigate to http://localhost:8000/math/double/ you will get: { \"detail\" : [ { \"loc\" : [ \"query\" , \"input\" ], \"msg\" : \"Missing required query parameter\" , \"type\" : \"value_error\" } ] } Nullable parameters Just because a parameter has a default value does not mean that it is nullable . For example, http://localhost:8000/items/?limit= means that limit has a value of \"\", which is considered a null value by OpenAPI. If you actually want to accept null values, you can make None an acceptable value for your parameter either using Optional[...] or Union[..., None] . On Python 3.10 you can also do int | None . Now if a null value is sent, it will be converted to None . It is even possible to have a nullable parameter with a non-null default value, for example to express \"the default limit is 10, but you can request all items (no/null limit)\": from typing import Optional from xpresso import App , FromQuery , Path fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_item ( skip : FromQuery [ int ] = 0 , limit : FromQuery [ Optional [ int ]] = 2 ): if limit is None : limit = len ( fake_items_db ) return fake_items_db [ skip : skip + limit ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) If you navigate to http://localhost:8000/items/?limit= you will get all of the items back (3): [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" } ] While not including the parameter ( http://localhost:8000/items/ ) at all will give you the default (2): [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" } ] Repeated query parameters Query parameters can be repeated, for example ?param=1&param=2 . You can extract these repeated query parmaeters into a Python list ( List[int] in this case). To accept repeated query parameters and extract them into a list, just pass the list type into FromQuery[...] : from typing import List from xpresso import App , FromQuery , Path fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_item ( prefix : FromQuery [ List [ str ]]): return [ item for item in fake_items_db if all ( item [ \"item_name\" ] . startswith ( p ) for p in prefix or []) ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Warning If no values are sent, you will get an empty list. To require at least one value, use parameter constraints, which you will learn about in the Paramter Constraints and Metadata section of the docs. Object query parameters For advanced use cases, Xpresso also supports object-valued query parameters. These can be extracted into a Pydantic model or a dictionary (including support for free-form query parameters). from typing import Optional from pydantic import BaseModel from xpresso import App , FromQuery , Path class Filter ( BaseModel ): prefix : str limit : int skip : int = 0 async def read_items ( filter : FromQuery [ Optional [ Filter ]], ) -> Optional [ Filter ]: return filter app = App ( routes = [ Path ( path = \"/items/\" , get = read_items , ), ] ) Now if you navigate to http://127.0.0.1:8000/items/?prefix=Ba&limit=1 you will get back the following JSON response: { \"limit\" : 1 , \"prefix\" : \"Ba\" , \"skip\" : 0 } Customizing deserialization Xpresso supports the full OpenAPI parameter serialization spec . For example, let's change the example above so that the paramters get serialized as ?filter[prefix]=Ba&filter[limit]=1 : from typing import Optional from pydantic import BaseModel from xpresso import App , Path , QueryParam from xpresso.typing import Annotated class Filter ( BaseModel ): prefix : str limit : int skip : int = 0 async def read_items ( filter : Annotated [ Optional [ Filter ], QueryParam ( style = \"deepObject\" ) ] ) -> Optional [ Filter ]: return filter app = App ( routes = [ Path ( path = \"/items/\" , get = read_items , ), ] ) Now if you navigate to http://127.0.0.1:8000/items/?filter[prefix]=Ba&filter[limit]=1 (note that the URL is URL encoded) you will get back the following JSON response: { \"limit\" : 1 , \"prefix\" : \"Ba\" , \"skip\" : 0 } This particular serialization is useful to support multiple objects with the same field name without name collisions.","title":"Query Parameters"},{"location":"tutorial/query_params/#query-parameters","text":"Query parameters are the named parameters that come after the ? in a URL: http://example.com/some/paths/?skip=1&limit=2 This URL has two simple query parameters: skip : value of 1 limit : value of 2 In Xpresso, these are extracted using FromQuery[...] , which is an alias for Annoated[..., QueryParam()] . Since they are part of the URL, they are always received as strings. But just like with path parameters, Xpresso can extract them and parse them into Python types and data structrues: from xpresso import App , FromQuery , Path fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_items ( skip : FromQuery [ int ] = 0 , limit : FromQuery [ int ] = 2 ): return fake_items_db [ skip : skip + limit ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_items , ), ] ) Now navigate to http://127.0.0.1:8000/items/?skip=1&limit=1 to see the query parameters being used to filter items. You should get the following response: [ { \"item_name\" : \"Bar\" } ]","title":"Query parameters"},{"location":"tutorial/query_params/#default-optional-parameters","text":"Unlike path parameters which are always required, query paramters can be optional. To make a query parameter optional, simply give the parameter a default value like we do for limit and skip . So, for our example above http://localhost:8000/items/?skip=0&limit=2 and http://localhost:8000/items/ will produce the same result: [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" } ] Of course if you don't give the parameter a default value, it will be required and an error response will automatically be returned if it is missing. For example, given: from typing import Dict from xpresso import App , FromQuery , Path async def double ( input : FromQuery [ int ]) -> Dict [ str , int ]: return { \"result\" : input * 2 } app = App ( routes = [ Path ( path = \"/math/double\" , get = double , ), ] ) If you navigate to http://localhost:8000/math/double/ you will get: { \"detail\" : [ { \"loc\" : [ \"query\" , \"input\" ], \"msg\" : \"Missing required query parameter\" , \"type\" : \"value_error\" } ] }","title":"Default (optional) parameters"},{"location":"tutorial/query_params/#nullable-parameters","text":"Just because a parameter has a default value does not mean that it is nullable . For example, http://localhost:8000/items/?limit= means that limit has a value of \"\", which is considered a null value by OpenAPI. If you actually want to accept null values, you can make None an acceptable value for your parameter either using Optional[...] or Union[..., None] . On Python 3.10 you can also do int | None . Now if a null value is sent, it will be converted to None . It is even possible to have a nullable parameter with a non-null default value, for example to express \"the default limit is 10, but you can request all items (no/null limit)\": from typing import Optional from xpresso import App , FromQuery , Path fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_item ( skip : FromQuery [ int ] = 0 , limit : FromQuery [ Optional [ int ]] = 2 ): if limit is None : limit = len ( fake_items_db ) return fake_items_db [ skip : skip + limit ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) If you navigate to http://localhost:8000/items/?limit= you will get all of the items back (3): [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" } ] While not including the parameter ( http://localhost:8000/items/ ) at all will give you the default (2): [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" } ]","title":"Nullable parameters"},{"location":"tutorial/query_params/#repeated-query-parameters","text":"Query parameters can be repeated, for example ?param=1&param=2 . You can extract these repeated query parmaeters into a Python list ( List[int] in this case). To accept repeated query parameters and extract them into a list, just pass the list type into FromQuery[...] : from typing import List from xpresso import App , FromQuery , Path fake_items_db = [ { \"item_name\" : \"Foo\" }, { \"item_name\" : \"Bar\" }, { \"item_name\" : \"Baz\" }, ] async def read_item ( prefix : FromQuery [ List [ str ]]): return [ item for item in fake_items_db if all ( item [ \"item_name\" ] . startswith ( p ) for p in prefix or []) ] app = App ( routes = [ Path ( path = \"/items/\" , get = read_item , ), ] ) Warning If no values are sent, you will get an empty list. To require at least one value, use parameter constraints, which you will learn about in the Paramter Constraints and Metadata section of the docs.","title":"Repeated query parameters"},{"location":"tutorial/query_params/#object-query-parameters","text":"For advanced use cases, Xpresso also supports object-valued query parameters. These can be extracted into a Pydantic model or a dictionary (including support for free-form query parameters). from typing import Optional from pydantic import BaseModel from xpresso import App , FromQuery , Path class Filter ( BaseModel ): prefix : str limit : int skip : int = 0 async def read_items ( filter : FromQuery [ Optional [ Filter ]], ) -> Optional [ Filter ]: return filter app = App ( routes = [ Path ( path = \"/items/\" , get = read_items , ), ] ) Now if you navigate to http://127.0.0.1:8000/items/?prefix=Ba&limit=1 you will get back the following JSON response: { \"limit\" : 1 , \"prefix\" : \"Ba\" , \"skip\" : 0 }","title":"Object query parameters"},{"location":"tutorial/query_params/#customizing-deserialization","text":"Xpresso supports the full OpenAPI parameter serialization spec . For example, let's change the example above so that the paramters get serialized as ?filter[prefix]=Ba&filter[limit]=1 : from typing import Optional from pydantic import BaseModel from xpresso import App , Path , QueryParam from xpresso.typing import Annotated class Filter ( BaseModel ): prefix : str limit : int skip : int = 0 async def read_items ( filter : Annotated [ Optional [ Filter ], QueryParam ( style = \"deepObject\" ) ] ) -> Optional [ Filter ]: return filter app = App ( routes = [ Path ( path = \"/items/\" , get = read_items , ), ] ) Now if you navigate to http://127.0.0.1:8000/items/?filter[prefix]=Ba&filter[limit]=1 (note that the URL is URL encoded) you will get back the following JSON response: { \"limit\" : 1 , \"prefix\" : \"Ba\" , \"skip\" : 0 } This particular serialization is useful to support multiple objects with the same field name without name collisions.","title":"Customizing deserialization"},{"location":"tutorial/routing/","text":"Routing Xpresso has a simple routing system, based on Starlette's routing system and the OpenAPI spec. There are 4 main players in Xpresso's routing system: Operation : this is equivalent to an OpenAPI operation. An operation is a unique combination of an HTTP method and a path, and has a 1:1 relationship with endpoint functions. Xpresso's Operation class is derived from a Starlette BaseRoute . Path : this is the equivalent of an OpenAPI PathItem. A Path can contain 1 Operation for each method (but does not have to). Paths are were you specify your actual path like /items/{item_id} . Path is derived from Starlette's Route . Router : similar to Starlette's router but only supporting adding routes at initialization ( @router.route does not exist in Xpresso). Additionally, it supports adding router-level dependencies, middleware and OpenAPI tags. App : this is the top-level application object where you configure your dependency injection container and OpenAPI docs. Functionality is similar to Starlette's Starlette application, but just like Router the dynamic methods like add_middleware() and add_exception_handler() are not supported. App also accepts middleware and dependencies, but these are just passed though to its router ( App.router ). All of these are meant to work with Starlette, so you can mount a Starlette application into Xpresso as a route using Mount , or use a Starlette router in the middle of Xpresso's routing system. from xpresso import App , Operation , Path , Router from xpresso.routing.mount import Mount async def items () -> None : ... path = Path ( \"/items\" , get = Operation ( items )) inner_mount = Mount ( path = \"/mount-again\" , routes = [ path ]) router = Router ( routes = [ inner_mount ]) outer_mount = Mount ( path = \"/mount\" , app = router ) app = App ( routes = [ outer_mount ]) See Starlette's routing docs for more general information on Starlette's routing system. Customizing OpenAPI schemas for Operation and Path Operation , Path and Router let you customize their OpenAPI schema. You can add descriptions, tags and detailed response information: Add tags via the tags parameter Exclude a specific Operation from the schema via the include_in_schema parameter Add a summary for the Operation via the summary parameter Add a description for the Operation via the description parameter (by default the endpoint function's docstring) Mark the operation as deprecated via the deprecated parameter Customize responses via the responses parameter from typing import List , Mapping from pydantic import BaseModel from xpresso import App , FromJson , Operation , Path , Response , Router from xpresso.openapi.models import Server from xpresso.responses import ResponseSpec from xpresso.routing.mount import Mount class Item ( BaseModel ): name : str price : float fake_items_db = { \"chair\" : Item ( name = \"chair\" , price = 30.29 ), \"hammer\" : Item ( name = \"hammer\" , price = 1.99 ), } async def get_items () -> Mapping [ str , Item ]: \"\"\"Docstring will be ignored\"\"\" return fake_items_db async def create_item ( item : FromJson [ Item ]) -> Response : \"\"\"Documentation from docstrings! You can use any valid markdown, for example lists: - Point 1 - Point 2 \"\"\" fake_items_db [ item . name ] = item return Response ( status_code = 204 ) async def delete_items ( items_to_delete : FromJson [ List [ str ]]) -> None : for item_name in items_to_delete : fake_items_db . pop ( item_name , None ) items = Path ( \"/items\" , get = Operation ( get_items , description = \"The **items** operation\" , summary = \"List all items\" , deprecated = True , tags = [ \"read\" ], ), post = Operation ( create_item , responses = { \"204\" : ResponseSpec ( description = \"Success\" )}, servers = [ Server ( url = \"https://us-east-1.example.com\" ), Server ( url = \"http://127.0.0.1:8000\" ), ], tags = [ \"write\" ], ), delete = Operation ( delete_items , include_in_schema = False , ), include_in_schema = True , # the default servers = [ Server ( url = \"http://127.0.0.1:8000\" )], tags = [ \"items\" ], ) app = App ( routes = [ Mount ( path = \"/v1\" , app = Router ( routes = [ items ], responses = { \"404\" : ResponseSpec ( description = \"Item not found\" ) }, tags = [ \"v1\" ], ), ) ] ) This will look something like this: Note Tags and responses accumulate. Responses are overwritten with the lower level of the routing tree tacking precedence, so setting the same status code on a Router and Operation will result in the Operation's version overwriting Router's. The servers array completely overwrites any parents: setting servers on Operation will overwrite all servers set on Routers or Path.","title":"Routing"},{"location":"tutorial/routing/#routing","text":"Xpresso has a simple routing system, based on Starlette's routing system and the OpenAPI spec. There are 4 main players in Xpresso's routing system: Operation : this is equivalent to an OpenAPI operation. An operation is a unique combination of an HTTP method and a path, and has a 1:1 relationship with endpoint functions. Xpresso's Operation class is derived from a Starlette BaseRoute . Path : this is the equivalent of an OpenAPI PathItem. A Path can contain 1 Operation for each method (but does not have to). Paths are were you specify your actual path like /items/{item_id} . Path is derived from Starlette's Route . Router : similar to Starlette's router but only supporting adding routes at initialization ( @router.route does not exist in Xpresso). Additionally, it supports adding router-level dependencies, middleware and OpenAPI tags. App : this is the top-level application object where you configure your dependency injection container and OpenAPI docs. Functionality is similar to Starlette's Starlette application, but just like Router the dynamic methods like add_middleware() and add_exception_handler() are not supported. App also accepts middleware and dependencies, but these are just passed though to its router ( App.router ). All of these are meant to work with Starlette, so you can mount a Starlette application into Xpresso as a route using Mount , or use a Starlette router in the middle of Xpresso's routing system. from xpresso import App , Operation , Path , Router from xpresso.routing.mount import Mount async def items () -> None : ... path = Path ( \"/items\" , get = Operation ( items )) inner_mount = Mount ( path = \"/mount-again\" , routes = [ path ]) router = Router ( routes = [ inner_mount ]) outer_mount = Mount ( path = \"/mount\" , app = router ) app = App ( routes = [ outer_mount ]) See Starlette's routing docs for more general information on Starlette's routing system.","title":"Routing"},{"location":"tutorial/routing/#customizing-openapi-schemas-for-operation-and-path","text":"Operation , Path and Router let you customize their OpenAPI schema. You can add descriptions, tags and detailed response information: Add tags via the tags parameter Exclude a specific Operation from the schema via the include_in_schema parameter Add a summary for the Operation via the summary parameter Add a description for the Operation via the description parameter (by default the endpoint function's docstring) Mark the operation as deprecated via the deprecated parameter Customize responses via the responses parameter from typing import List , Mapping from pydantic import BaseModel from xpresso import App , FromJson , Operation , Path , Response , Router from xpresso.openapi.models import Server from xpresso.responses import ResponseSpec from xpresso.routing.mount import Mount class Item ( BaseModel ): name : str price : float fake_items_db = { \"chair\" : Item ( name = \"chair\" , price = 30.29 ), \"hammer\" : Item ( name = \"hammer\" , price = 1.99 ), } async def get_items () -> Mapping [ str , Item ]: \"\"\"Docstring will be ignored\"\"\" return fake_items_db async def create_item ( item : FromJson [ Item ]) -> Response : \"\"\"Documentation from docstrings! You can use any valid markdown, for example lists: - Point 1 - Point 2 \"\"\" fake_items_db [ item . name ] = item return Response ( status_code = 204 ) async def delete_items ( items_to_delete : FromJson [ List [ str ]]) -> None : for item_name in items_to_delete : fake_items_db . pop ( item_name , None ) items = Path ( \"/items\" , get = Operation ( get_items , description = \"The **items** operation\" , summary = \"List all items\" , deprecated = True , tags = [ \"read\" ], ), post = Operation ( create_item , responses = { \"204\" : ResponseSpec ( description = \"Success\" )}, servers = [ Server ( url = \"https://us-east-1.example.com\" ), Server ( url = \"http://127.0.0.1:8000\" ), ], tags = [ \"write\" ], ), delete = Operation ( delete_items , include_in_schema = False , ), include_in_schema = True , # the default servers = [ Server ( url = \"http://127.0.0.1:8000\" )], tags = [ \"items\" ], ) app = App ( routes = [ Mount ( path = \"/v1\" , app = Router ( routes = [ items ], responses = { \"404\" : ResponseSpec ( description = \"Item not found\" ) }, tags = [ \"v1\" ], ), ) ] ) This will look something like this: Note Tags and responses accumulate. Responses are overwritten with the lower level of the routing tree tacking precedence, so setting the same status code on a Router and Operation will result in the Operation's version overwriting Router's. The servers array completely overwrites any parents: setting servers on Operation will overwrite all servers set on Routers or Path.","title":"Customizing OpenAPI schemas for Operation and Path"},{"location":"tutorial/dependencies/","text":"Dependency Injection Xpresso has a built in Dependency Injection system. You do not need to know what Dependency Injection is or be an expert in design patterns to get started. Background Let's look at a simple case of a function needing an HTTP client. For this example, we'll use httpx . import httpx def make_request () -> int : client = httpx . Client ( base_url = \"http://example.com/v1/\" ) resp = client . get ( \"/\" ) return resp . status_code print ( make_request ()) This example does not use dependency injection because httpx.Client (the dependency ) is created by the the dependant ( make_request() ). The most basic form of dependency injection would be to \"inject\" an instance of httpx.Client into make_request() : import httpx def make_request ( client : httpx . Client ) -> int : resp = client . get ( \"/\" ) return resp . status_code client = httpx . Client ( base_url = \"http://example.com/v1/\" ) print ( make_request ( client )) This already gives us a lot of flexibility: Shared logic : if http://example.com/v1/ gets updated to http://example.com/v2/ , we only have to change that in one place, and we don't have to change our tests. Testability : we can test make_request() with an httpx.Client instance using a MockTransport . Performance : http clients like httpx and similar things like database clients tend to re-use connections. So you can get a large performance benefit from sharing the same client / connections across your application. There are many more benefits to dependency injection, and you can go really deep into the topic if you'd like, but for now this is enough background. Dependency Injection in Xpresso Xpresso's dependency injection API is modeled after FastAPI . It is implemented as a standalone package called di . The simplest form of dependency injection is requesting a dependency in your endpoint function. For simple cases, all we need to do is add a type annotation: import httpx from xpresso import App , Path async def echo_url ( client : httpx . AsyncClient ) -> str : resp = await client . get ( \"https://httpbin.org/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) If you run the app (make a file called example.py , copy the source code above and run uvicorn example:app ) and navigate to http://127.0.0.1:8000/echo/url you will get the following as a response: \"https://httpbin.org/get\" What happened in the background? The dependency injection system ( di ) auto-wired the dependency on httpx.AsyncClient . This means that it recognized that our endpoint function needed an instance of that class and so it created that class and injected it. This works well for simple cases (classes that do not have any dependencies or where all of the parameters are themselves resolvable by di ) and when it works, it may be all you need! Explicit dependencies with markers There are many situations in which you can't rely on auto-wiring. For example, if the value is coming from a function. In these cases, you need to use an explicit marker. In this example, we'll use an explicit marker to customize the base_url option to httpx.AsyncClient . First, we declare a dependency function. This function will just create the client with customized parameters and return it. import httpx from xpresso import App , Depends , Path from xpresso.typing import Annotated def get_client () -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = \"https://httpbin.org\" ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Next, we'll create the Marker for our dependency. This is what the dependency injection system will look for. You can declare it in the endpoint function's signature, but often it is convenient to declare Markers as a type alias to avoid cluttering the function signature: import httpx from xpresso import App , Depends , Path from xpresso.typing import Annotated def get_client () -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = \"https://httpbin.org\" ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Tip For simple cases like this, you can even use a lambda function: Depends(lambda: httpx.AsyncClient(...)) Just be conscious of legibility! Since we are now specifying the base_url when we construct the httpx.AsyncClient , we can just use \"/get\" as the URL in our endpoint function: import httpx from xpresso import App , Depends , Path from xpresso.typing import Annotated def get_client () -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = \"https://httpbin.org\" ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) That's it! Markers provide a powerful system for telling the dependency injection system how to create and manage your dependencies. They control construction, concurrency, caching and wiring, which are all topics we will explore in future chapters.","title":"Introduction"},{"location":"tutorial/dependencies/#dependency-injection","text":"Xpresso has a built in Dependency Injection system. You do not need to know what Dependency Injection is or be an expert in design patterns to get started.","title":"Dependency Injection"},{"location":"tutorial/dependencies/#background","text":"Let's look at a simple case of a function needing an HTTP client. For this example, we'll use httpx . import httpx def make_request () -> int : client = httpx . Client ( base_url = \"http://example.com/v1/\" ) resp = client . get ( \"/\" ) return resp . status_code print ( make_request ()) This example does not use dependency injection because httpx.Client (the dependency ) is created by the the dependant ( make_request() ). The most basic form of dependency injection would be to \"inject\" an instance of httpx.Client into make_request() : import httpx def make_request ( client : httpx . Client ) -> int : resp = client . get ( \"/\" ) return resp . status_code client = httpx . Client ( base_url = \"http://example.com/v1/\" ) print ( make_request ( client )) This already gives us a lot of flexibility: Shared logic : if http://example.com/v1/ gets updated to http://example.com/v2/ , we only have to change that in one place, and we don't have to change our tests. Testability : we can test make_request() with an httpx.Client instance using a MockTransport . Performance : http clients like httpx and similar things like database clients tend to re-use connections. So you can get a large performance benefit from sharing the same client / connections across your application. There are many more benefits to dependency injection, and you can go really deep into the topic if you'd like, but for now this is enough background.","title":"Background"},{"location":"tutorial/dependencies/#dependency-injection-in-xpresso","text":"Xpresso's dependency injection API is modeled after FastAPI . It is implemented as a standalone package called di . The simplest form of dependency injection is requesting a dependency in your endpoint function. For simple cases, all we need to do is add a type annotation: import httpx from xpresso import App , Path async def echo_url ( client : httpx . AsyncClient ) -> str : resp = await client . get ( \"https://httpbin.org/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) If you run the app (make a file called example.py , copy the source code above and run uvicorn example:app ) and navigate to http://127.0.0.1:8000/echo/url you will get the following as a response: \"https://httpbin.org/get\"","title":"Dependency Injection in Xpresso"},{"location":"tutorial/dependencies/#what-happened-in-the-background","text":"The dependency injection system ( di ) auto-wired the dependency on httpx.AsyncClient . This means that it recognized that our endpoint function needed an instance of that class and so it created that class and injected it. This works well for simple cases (classes that do not have any dependencies or where all of the parameters are themselves resolvable by di ) and when it works, it may be all you need!","title":"What happened in the background?"},{"location":"tutorial/dependencies/#explicit-dependencies-with-markers","text":"There are many situations in which you can't rely on auto-wiring. For example, if the value is coming from a function. In these cases, you need to use an explicit marker. In this example, we'll use an explicit marker to customize the base_url option to httpx.AsyncClient . First, we declare a dependency function. This function will just create the client with customized parameters and return it. import httpx from xpresso import App , Depends , Path from xpresso.typing import Annotated def get_client () -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = \"https://httpbin.org\" ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Next, we'll create the Marker for our dependency. This is what the dependency injection system will look for. You can declare it in the endpoint function's signature, but often it is convenient to declare Markers as a type alias to avoid cluttering the function signature: import httpx from xpresso import App , Depends , Path from xpresso.typing import Annotated def get_client () -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = \"https://httpbin.org\" ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Tip For simple cases like this, you can even use a lambda function: Depends(lambda: httpx.AsyncClient(...)) Just be conscious of legibility! Since we are now specifying the base_url when we construct the httpx.AsyncClient , we can just use \"/get\" as the URL in our endpoint function: import httpx from xpresso import App , Depends , Path from xpresso.typing import Annotated def get_client () -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = \"https://httpbin.org\" ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) That's it! Markers provide a powerful system for telling the dependency injection system how to create and manage your dependencies. They control construction, concurrency, caching and wiring, which are all topics we will explore in future chapters.","title":"Explicit dependencies with markers"},{"location":"tutorial/dependencies/http-params/","text":"HTTP Parameters in Dependencies Your dependencies can depend on HTTP parameters. For example, you can get a query parameter from within a dependency. This can be useful to create reusable groups of parameters: from pydantic import BaseModel from xpresso import App , FromQuery , Path class CurrentUser ( BaseModel ): username : FromQuery [ str ] async def echo_user ( user : CurrentUser ) -> CurrentUser : return user app = App ( routes = [ Path ( \"/echo/user\" , get = echo_user , ) ] ) This applies to parameters as well as request bodies.","title":"HTTP Parameter Dependencies"},{"location":"tutorial/dependencies/http-params/#http-parameters-in-dependencies","text":"Your dependencies can depend on HTTP parameters. For example, you can get a query parameter from within a dependency. This can be useful to create reusable groups of parameters: from pydantic import BaseModel from xpresso import App , FromQuery , Path class CurrentUser ( BaseModel ): username : FromQuery [ str ] async def echo_user ( user : CurrentUser ) -> CurrentUser : return user app = App ( routes = [ Path ( \"/echo/user\" , get = echo_user , ) ] ) This applies to parameters as well as request bodies.","title":"HTTP Parameters in Dependencies"},{"location":"tutorial/dependencies/lifecycle/","text":"Dependency Lifecycle Up until now we've only seen dependencies that return a value directly. But often you'll want to do some work (like creating a database connection), yield that thing (the connection object) and then do some more work to teardown that thing (for example closing the connection). Xpresso lets you declare this type of execution using context manager dependencies . These are dependencies that use the yield keyword once to give back control and then wait until they get back control to run their teardown . Note Any function func() that could be passed to @contextlib.contextmanager or @contextlib.asynccontextmanager will work. We can apply this concept to our httpx.AsyncClient example to clean up the client after we are done using it. All we have to do is change our function to be a context manager like function (an async one in this case) and then use httpx.AsyncClient 's context manager within the function: from typing import AsyncGenerator import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel ()) ] async def get_client ( config : HttpBinConfig , ) -> AsyncGenerator [ httpx . AsyncClient , None ]: async with httpx . AsyncClient ( base_url = config . url ) as client : yield client HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Check Did you notice that we also converted get_client() from a def function to an async def function? Making changes like this is super easy using Xpresso's dependency injection system! It decouples you from execution so that you can mix and match sync and async dependencies without worrying about await ing from a sync dependency and other complexities of cooperative concurrency. Tip It is always best to use httpx.AsyncClient as a context manager to ensure that connections get cleaned up. Otherwise, httpx will give you a warning which you'd see in your logs. Once again, nothing will change from the application user's perspective, but our backend is now a lot more resilient! The order of execution here is get_client() -> echo_headers() -> get_client() and is roughly equivalent to: async with asynccontextmanager ( get_client ( HttpBinConfigModel ())) as client : await echo_headers ( client )","title":"Dependency Lifecycle"},{"location":"tutorial/dependencies/lifecycle/#dependency-lifecycle","text":"Up until now we've only seen dependencies that return a value directly. But often you'll want to do some work (like creating a database connection), yield that thing (the connection object) and then do some more work to teardown that thing (for example closing the connection). Xpresso lets you declare this type of execution using context manager dependencies . These are dependencies that use the yield keyword once to give back control and then wait until they get back control to run their teardown . Note Any function func() that could be passed to @contextlib.contextmanager or @contextlib.asynccontextmanager will work. We can apply this concept to our httpx.AsyncClient example to clean up the client after we are done using it. All we have to do is change our function to be a context manager like function (an async one in this case) and then use httpx.AsyncClient 's context manager within the function: from typing import AsyncGenerator import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel ()) ] async def get_client ( config : HttpBinConfig , ) -> AsyncGenerator [ httpx . AsyncClient , None ]: async with httpx . AsyncClient ( base_url = config . url ) as client : yield client HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Check Did you notice that we also converted get_client() from a def function to an async def function? Making changes like this is super easy using Xpresso's dependency injection system! It decouples you from execution so that you can mix and match sync and async dependencies without worrying about await ing from a sync dependency and other complexities of cooperative concurrency. Tip It is always best to use httpx.AsyncClient as a context manager to ensure that connections get cleaned up. Otherwise, httpx will give you a warning which you'd see in your logs. Once again, nothing will change from the application user's perspective, but our backend is now a lot more resilient! The order of execution here is get_client() -> echo_headers() -> get_client() and is roughly equivalent to: async with asynccontextmanager ( get_client ( HttpBinConfigModel ())) as client : await echo_headers ( client )","title":"Dependency Lifecycle"},{"location":"tutorial/dependencies/nested/","text":"Nested dependencies Dependencies can have sub-dependencies, which in turn can have more sub-dependencies, creating a nested structure of dependencies. Xpresso supports arbitrarily deep nesting of dependencies and will organize them so that each dependency only gets executed once all of its sub-dependencies have already been executed. Tip The technical term for this sort of structure is a Directed Acyclic Graph (DAG for short). But don't worry, you don't need to understand graph theory to use nested dependencies. To build nested dependencies, just create a dependency that depends on another dependency. Continuing with our example of httpx.AsyncClient , we can create a dependency that holds the configuration for the client, namely the base_url for HTTPBin. We'll start by declaring a Pydantic model using Pydantic's config management system : import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel ()) ] def get_client ( config : HttpBinConfig ) -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = config . url ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) pydantic.BaseSettings subclasses are actually a great example of things that cannot be auto-wired by the dependency injection system (in this case, it is for various technical reasons that are not relevant to this tutorial). But we can easily tell the dependency injection system to just build the class with no parameters by default: import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel ()) ] def get_client ( config : HttpBinConfig ) -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = config . url ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) The last thing we need to do is add the dependency to get_client() and use the config inside of get_client() : import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel ()) ] def get_client ( config : HttpBinConfig ) -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = config . url ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Now the application will behave exactly the same as before except that you can override the URL used for HTTPBin with the HTTPBIN_URL environment variable. For example, try setting it HTTPBIN_URL=http://httpbin.org ( http instead of https ).","title":"Nested Dependencies"},{"location":"tutorial/dependencies/nested/#nested-dependencies","text":"Dependencies can have sub-dependencies, which in turn can have more sub-dependencies, creating a nested structure of dependencies. Xpresso supports arbitrarily deep nesting of dependencies and will organize them so that each dependency only gets executed once all of its sub-dependencies have already been executed. Tip The technical term for this sort of structure is a Directed Acyclic Graph (DAG for short). But don't worry, you don't need to understand graph theory to use nested dependencies. To build nested dependencies, just create a dependency that depends on another dependency. Continuing with our example of httpx.AsyncClient , we can create a dependency that holds the configuration for the client, namely the base_url for HTTPBin. We'll start by declaring a Pydantic model using Pydantic's config management system : import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel ()) ] def get_client ( config : HttpBinConfig ) -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = config . url ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) pydantic.BaseSettings subclasses are actually a great example of things that cannot be auto-wired by the dependency injection system (in this case, it is for various technical reasons that are not relevant to this tutorial). But we can easily tell the dependency injection system to just build the class with no parameters by default: import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel ()) ] def get_client ( config : HttpBinConfig ) -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = config . url ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) The last thing we need to do is add the dependency to get_client() and use the config inside of get_client() : import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel ()) ] def get_client ( config : HttpBinConfig ) -> httpx . AsyncClient : return httpx . AsyncClient ( base_url = config . url ) HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client )] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Now the application will behave exactly the same as before except that you can override the URL used for HTTPBin with the HTTPBIN_URL environment variable. For example, try setting it HTTPBIN_URL=http://httpbin.org ( http instead of https ).","title":"Nested dependencies"},{"location":"tutorial/dependencies/scopes/","text":"Scopes In our last tutorial with httpx.AsyncClient we left off at dependency lifecycles . As you may have noticed, we are creating and tearing down the httpx.AsyncClient instance for each incoming request. This is very inefficient! Really what we want to do is create the httpx.AsyncClient once, when our application starts up, and then use the same instance for each request, only tearing down the client when our app shuts down. To achieve this, we need to introduce scopes . Scopes let you control the \"lifetime\" of your dependency and are inspired by pytest 's fixture system. In Pytest you may have used scopes like \"session\", \"module\" or \"function\". In Xpresso there are three scopes available: \"endpoint\" : the dependency is created right before calling the endpoint function and torn down right after your function returns, but before the response is sent to the client. \"connection\" (default): this scope is entered before the endpoint scope and before calling your endpoint function and is torn down right after the response is sent to the client. \"app\" : the outermost scope. Dependencies in this scope are tied to the [lifespan] of the application. So for our use case, we'll be wanting to use the \"app\" scope for httpx.AsyncClient : from typing import AsyncGenerator import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel (), scope = \"app\" ), ] async def get_client ( config : HttpBinConfig , ) -> AsyncGenerator [ httpx . AsyncClient , None ]: async with httpx . AsyncClient ( base_url = config . url ) as client : yield client HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client , scope = \"app\" ) ] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Everything else can stay the same, this is all we need! Attention You may notice we also had to change the HttpBinConfig marker to the \"app\" scope. Just like in Pytest, where a \"session\" scoped fixture can't depend on a \"function\" scoped fixture, in Xpresso an \"app\" scoped fixture can't depend on an \"endpoint\" scoped fixture, so we are forced to make HttpBinConfig an \"app\" scoped fixture. If you run this and navigate to http://127.0.0.1:8000/echo/url the response will be the same, but you will probably notice reduced latency if you refresh to make several requests.","title":"Scopes"},{"location":"tutorial/dependencies/scopes/#scopes","text":"In our last tutorial with httpx.AsyncClient we left off at dependency lifecycles . As you may have noticed, we are creating and tearing down the httpx.AsyncClient instance for each incoming request. This is very inefficient! Really what we want to do is create the httpx.AsyncClient once, when our application starts up, and then use the same instance for each request, only tearing down the client when our app shuts down. To achieve this, we need to introduce scopes . Scopes let you control the \"lifetime\" of your dependency and are inspired by pytest 's fixture system. In Pytest you may have used scopes like \"session\", \"module\" or \"function\". In Xpresso there are three scopes available: \"endpoint\" : the dependency is created right before calling the endpoint function and torn down right after your function returns, but before the response is sent to the client. \"connection\" (default): this scope is entered before the endpoint scope and before calling your endpoint function and is torn down right after the response is sent to the client. \"app\" : the outermost scope. Dependencies in this scope are tied to the [lifespan] of the application. So for our use case, we'll be wanting to use the \"app\" scope for httpx.AsyncClient : from typing import AsyncGenerator import httpx from pydantic import BaseSettings from xpresso import App , Depends , Path from xpresso.typing import Annotated class HttpBinConfigModel ( BaseSettings ): url : str = \"https://httpbin.org\" class Config ( BaseSettings . Config ): env_prefix = \"HTTPBIN_\" HttpBinConfig = Annotated [ HttpBinConfigModel , Depends ( lambda : HttpBinConfigModel (), scope = \"app\" ), ] async def get_client ( config : HttpBinConfig , ) -> AsyncGenerator [ httpx . AsyncClient , None ]: async with httpx . AsyncClient ( base_url = config . url ) as client : yield client HttpbinClient = Annotated [ httpx . AsyncClient , Depends ( get_client , scope = \"app\" ) ] async def echo_url ( client : HttpbinClient ) -> str : resp = await client . get ( \"/get\" ) resp . raise_for_status () # or some other error handling return resp . json ()[ \"url\" ] app = App ( routes = [ Path ( \"/echo/url\" , get = echo_url , ) ] ) Everything else can stay the same, this is all we need! Attention You may notice we also had to change the HttpBinConfig marker to the \"app\" scope. Just like in Pytest, where a \"session\" scoped fixture can't depend on a \"function\" scoped fixture, in Xpresso an \"app\" scoped fixture can't depend on an \"endpoint\" scoped fixture, so we are forced to make HttpBinConfig an \"app\" scoped fixture. If you run this and navigate to http://127.0.0.1:8000/echo/url the response will be the same, but you will probably notice reduced latency if you refresh to make several requests.","title":"Scopes"},{"location":"tutorial/dependencies/shared/","text":"Dependencies Shared at the Operation, Path and Route level Sometimes you will have dependencies that are not used directly in your endpoint function but you still need executed. For example, you may have a Security dependency that enforces access but does not return any meaningful value. You may also want a dependency to apply to all of the operations of a Path, or even all of the Paths managed by a Router (including mounted routers). For these use cases, Xpresso lets you add dependencies directly to the Operation, Path or Router. As an example, let's create a very basic authorization system. We'll have an array query parameter called roles that contains the roles the user making the request can act as. Danger This is not a real authorization system. In a secure production setting, you would use something like OAuth2, not query parameters. First we'll make a factory function that, given a set of roles, creates a function that enforces those roles and returns a 403 response if any are missing: from typing import Callable , FrozenSet , Optional from xpresso import ( App , Depends , FromPath , FromQuery , HTTPException , Operation , Path , ) def require_roles ( * roles : str ) -> Callable [ ... , None ]: role_set = frozenset ( roles ) def enforce_roles ( roles : FromQuery [ Optional [ FrozenSet [ str ]]] = None , ) -> None : missing_roles = role_set . difference ( roles or frozenset ()) if missing_roles : raise HTTPException ( 403 , f \"Missing roles: { list ( missing_roles ) } \" ) return enforce_roles async def delete_item () -> None : ... async def get_item ( item_id : FromPath [ str ]) -> str : return item_id app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item , # no extra roles required delete = Operation ( endpoint = delete_item , dependencies = [ Depends ( require_roles ( \"items-admin\" ))], ), dependencies = [ Depends ( require_roles ( \"items-user\" ))], ) ], dependencies = [ Depends ( require_roles ( \"user\" ))], ) Next we'll declare a couple of endpoints, one to delete an item and one to get an item: from typing import Callable , FrozenSet , Optional from xpresso import ( App , Depends , FromPath , FromQuery , HTTPException , Operation , Path , ) def require_roles ( * roles : str ) -> Callable [ ... , None ]: role_set = frozenset ( roles ) def enforce_roles ( roles : FromQuery [ Optional [ FrozenSet [ str ]]] = None , ) -> None : missing_roles = role_set . difference ( roles or frozenset ()) if missing_roles : raise HTTPException ( 403 , f \"Missing roles: { list ( missing_roles ) } \" ) return enforce_roles async def delete_item () -> None : ... async def get_item ( item_id : FromPath [ str ]) -> str : return item_id app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item , # no extra roles required delete = Operation ( endpoint = delete_item , dependencies = [ Depends ( require_roles ( \"items-admin\" ))], ), dependencies = [ Depends ( require_roles ( \"items-user\" ))], ) ], dependencies = [ Depends ( require_roles ( \"user\" ))], ) Finally, we create our App and add dependencies to the App, Path and Operations: from typing import Callable , FrozenSet , Optional from xpresso import ( App , Depends , FromPath , FromQuery , HTTPException , Operation , Path , ) def require_roles ( * roles : str ) -> Callable [ ... , None ]: role_set = frozenset ( roles ) def enforce_roles ( roles : FromQuery [ Optional [ FrozenSet [ str ]]] = None , ) -> None : missing_roles = role_set . difference ( roles or frozenset ()) if missing_roles : raise HTTPException ( 403 , f \"Missing roles: { list ( missing_roles ) } \" ) return enforce_roles async def delete_item () -> None : ... async def get_item ( item_id : FromPath [ str ]) -> str : return item_id app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item , # no extra roles required delete = Operation ( endpoint = delete_item , dependencies = [ Depends ( require_roles ( \"items-admin\" ))], ), dependencies = [ Depends ( require_roles ( \"items-user\" ))], ) ], dependencies = [ Depends ( require_roles ( \"user\" ))], ) Note The dependencies parameter to App gets passed directly to App.router . The same parameter is available on Router itself. Run this app (save the source code above to example.py and run it using uvicorn example:app ) and navigate to http://127.0.0.1:8000/items/foobar and you will get the following response: { \"detail\" : \"Missing roles: ['user']\" } So let's add the \"user\" role to our query string: http://127.0.0.1:8000/items/foobar?roles=user . Now we get a new error: { \"detail\" : \"Missing roles: ['items-user']\" } Adding the \"items-user\" role we can now \"get\" an item by navigating to http://127.0.0.1:8000/items/foobar?roles=user,items-user \"foobar\" Middleware, error handlers and dependencies Generally speaking anything you can do with middleware or error handlers you can also do with dependencies. The main advantage of using the dependency injection system is that dependencies can be applied at multiple levels (like in the example above) while middleware can only apply to the entire application. Middleware also applies to the entire application, so if you only want to profile or log certain routes it can be cumbersome and inefficient.","title":"Shared Dependencies"},{"location":"tutorial/dependencies/shared/#dependencies-shared-at-the-operation-path-and-route-level","text":"Sometimes you will have dependencies that are not used directly in your endpoint function but you still need executed. For example, you may have a Security dependency that enforces access but does not return any meaningful value. You may also want a dependency to apply to all of the operations of a Path, or even all of the Paths managed by a Router (including mounted routers). For these use cases, Xpresso lets you add dependencies directly to the Operation, Path or Router. As an example, let's create a very basic authorization system. We'll have an array query parameter called roles that contains the roles the user making the request can act as. Danger This is not a real authorization system. In a secure production setting, you would use something like OAuth2, not query parameters. First we'll make a factory function that, given a set of roles, creates a function that enforces those roles and returns a 403 response if any are missing: from typing import Callable , FrozenSet , Optional from xpresso import ( App , Depends , FromPath , FromQuery , HTTPException , Operation , Path , ) def require_roles ( * roles : str ) -> Callable [ ... , None ]: role_set = frozenset ( roles ) def enforce_roles ( roles : FromQuery [ Optional [ FrozenSet [ str ]]] = None , ) -> None : missing_roles = role_set . difference ( roles or frozenset ()) if missing_roles : raise HTTPException ( 403 , f \"Missing roles: { list ( missing_roles ) } \" ) return enforce_roles async def delete_item () -> None : ... async def get_item ( item_id : FromPath [ str ]) -> str : return item_id app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item , # no extra roles required delete = Operation ( endpoint = delete_item , dependencies = [ Depends ( require_roles ( \"items-admin\" ))], ), dependencies = [ Depends ( require_roles ( \"items-user\" ))], ) ], dependencies = [ Depends ( require_roles ( \"user\" ))], ) Next we'll declare a couple of endpoints, one to delete an item and one to get an item: from typing import Callable , FrozenSet , Optional from xpresso import ( App , Depends , FromPath , FromQuery , HTTPException , Operation , Path , ) def require_roles ( * roles : str ) -> Callable [ ... , None ]: role_set = frozenset ( roles ) def enforce_roles ( roles : FromQuery [ Optional [ FrozenSet [ str ]]] = None , ) -> None : missing_roles = role_set . difference ( roles or frozenset ()) if missing_roles : raise HTTPException ( 403 , f \"Missing roles: { list ( missing_roles ) } \" ) return enforce_roles async def delete_item () -> None : ... async def get_item ( item_id : FromPath [ str ]) -> str : return item_id app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item , # no extra roles required delete = Operation ( endpoint = delete_item , dependencies = [ Depends ( require_roles ( \"items-admin\" ))], ), dependencies = [ Depends ( require_roles ( \"items-user\" ))], ) ], dependencies = [ Depends ( require_roles ( \"user\" ))], ) Finally, we create our App and add dependencies to the App, Path and Operations: from typing import Callable , FrozenSet , Optional from xpresso import ( App , Depends , FromPath , FromQuery , HTTPException , Operation , Path , ) def require_roles ( * roles : str ) -> Callable [ ... , None ]: role_set = frozenset ( roles ) def enforce_roles ( roles : FromQuery [ Optional [ FrozenSet [ str ]]] = None , ) -> None : missing_roles = role_set . difference ( roles or frozenset ()) if missing_roles : raise HTTPException ( 403 , f \"Missing roles: { list ( missing_roles ) } \" ) return enforce_roles async def delete_item () -> None : ... async def get_item ( item_id : FromPath [ str ]) -> str : return item_id app = App ( routes = [ Path ( \"/items/ {item_id} \" , get = get_item , # no extra roles required delete = Operation ( endpoint = delete_item , dependencies = [ Depends ( require_roles ( \"items-admin\" ))], ), dependencies = [ Depends ( require_roles ( \"items-user\" ))], ) ], dependencies = [ Depends ( require_roles ( \"user\" ))], ) Note The dependencies parameter to App gets passed directly to App.router . The same parameter is available on Router itself. Run this app (save the source code above to example.py and run it using uvicorn example:app ) and navigate to http://127.0.0.1:8000/items/foobar and you will get the following response: { \"detail\" : \"Missing roles: ['user']\" } So let's add the \"user\" role to our query string: http://127.0.0.1:8000/items/foobar?roles=user . Now we get a new error: { \"detail\" : \"Missing roles: ['items-user']\" } Adding the \"items-user\" role we can now \"get\" an item by navigating to http://127.0.0.1:8000/items/foobar?roles=user,items-user \"foobar\"","title":"Dependencies Shared at the Operation, Path and Route level"},{"location":"tutorial/dependencies/shared/#middleware-error-handlers-and-dependencies","text":"Generally speaking anything you can do with middleware or error handlers you can also do with dependencies. The main advantage of using the dependency injection system is that dependencies can be applied at multiple levels (like in the example above) while middleware can only apply to the entire application. Middleware also applies to the entire application, so if you only want to profile or log certain routes it can be cumbersome and inefficient.","title":"Middleware, error handlers and dependencies"},{"location":"tutorial/middleware/","text":"Middleware Middleware is code that runs in between the client and your endpoint. More specifically, middleware runs before routing (more on this later). Middleware in Xpresso is just standard ASGI middleware. This enables interoperability with existing middleware written for other ASGI frameworks. In fact, because Xpresso is based on Starlette it already ships with some of the most useful middleware out of the box. See Starlette's Middleware Docs for an exhaustive list of the included middleware. Differences between middleware and dependencies Middleware and dependencies are quite similar, but have some important differences. Here are a couple differences worth highlighting that you help you in deciding when to use middleware and when to use dependencies: Middleware runs before routing, dependencies run after routing. If you need to modify the request path or want to do performance profiling, you'll need to use middleware. The dependency system is specific to Xpresso, ASGI middleware is a standard. You are much more likely to find an existing middleware for your use than you are an Xpresso dependency. Middleware is generally more performant, unless you need to do work after the response is sent back to the user (which dependencies can do but middleware can not) Dependencies can pass in values to your endpoint function, middleware can not (directly) pass data to your endpoint function. Middleware can return a Response directly to your client, without passing through your endpoint function. Dependencies can only do this by raising a HTTPException . Middleware on Routers Unlike FastAPI and Starlette where middleware is installed on the \"application\" object ( fastapi.applications.FastAPI in FastAPI and starlette.applications.Starlette in Starlette), in Xpresso middleware is installed on Router . This gives you the ability to selectively apply middleware to only some routes (by mounting a Router on a subpath using Mount ). Otherwise, the semantics and usage of middleware are still the same: it runs before routing (for the router it is installed on) and it manages both requests and responses. Example: CORSMiddleware As an example of applying a generic ASGI middleware to Xpresso, we'll use Starlette's CORSMiddleware . CORS stands for Cross Origin Resource Sharing , and is an important security feature of modern web applications. In short, CORS lets you control what origins (a unique combination of protocol, port and host) requests to your API are allowed to come from. This prevents a malicious site from using authentication credentials stored in your browser to send requests to your backend. Since CORS is usually something you worry about in the later stages of your app's development, we'll use a more production ready structure here. Instead of creating an app object at the global scope, we'll write app factory functions that create different apps depending on the configuration. This is one way to make an app work in both a production environment and locally for debugging. We will also be using [Router Middleware] to selectively apply middleware to only some routes. In particular, we'll leave the /health endpoint open to the public internet (you may or may not want to do this in production; this tutorial is not meant to be a security guide). Start by defining your data models and endpoint functions from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config ) Next define a configuration model for your application using Pydantic's Settings Management : from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config ) Now define a create_app() method that accepts a config and returns an App: from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config ) Finally, make a create_production_app() method that will load AppConfig from environment variables and pass that to create_app() : from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config ) For debugging or tests you might create a create_debug_app() method that passes in the cors_origin parameter to AppConfig or sets it as an environment variable before calling AppConfig() : from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config )","title":"Introduction"},{"location":"tutorial/middleware/#middleware","text":"Middleware is code that runs in between the client and your endpoint. More specifically, middleware runs before routing (more on this later). Middleware in Xpresso is just standard ASGI middleware. This enables interoperability with existing middleware written for other ASGI frameworks. In fact, because Xpresso is based on Starlette it already ships with some of the most useful middleware out of the box. See Starlette's Middleware Docs for an exhaustive list of the included middleware.","title":"Middleware"},{"location":"tutorial/middleware/#differences-between-middleware-and-dependencies","text":"Middleware and dependencies are quite similar, but have some important differences. Here are a couple differences worth highlighting that you help you in deciding when to use middleware and when to use dependencies: Middleware runs before routing, dependencies run after routing. If you need to modify the request path or want to do performance profiling, you'll need to use middleware. The dependency system is specific to Xpresso, ASGI middleware is a standard. You are much more likely to find an existing middleware for your use than you are an Xpresso dependency. Middleware is generally more performant, unless you need to do work after the response is sent back to the user (which dependencies can do but middleware can not) Dependencies can pass in values to your endpoint function, middleware can not (directly) pass data to your endpoint function. Middleware can return a Response directly to your client, without passing through your endpoint function. Dependencies can only do this by raising a HTTPException .","title":"Differences between middleware and dependencies"},{"location":"tutorial/middleware/#middleware-on-routers","text":"Unlike FastAPI and Starlette where middleware is installed on the \"application\" object ( fastapi.applications.FastAPI in FastAPI and starlette.applications.Starlette in Starlette), in Xpresso middleware is installed on Router . This gives you the ability to selectively apply middleware to only some routes (by mounting a Router on a subpath using Mount ). Otherwise, the semantics and usage of middleware are still the same: it runs before routing (for the router it is installed on) and it manages both requests and responses.","title":"Middleware on Routers"},{"location":"tutorial/middleware/#example-corsmiddleware","text":"As an example of applying a generic ASGI middleware to Xpresso, we'll use Starlette's CORSMiddleware . CORS stands for Cross Origin Resource Sharing , and is an important security feature of modern web applications. In short, CORS lets you control what origins (a unique combination of protocol, port and host) requests to your API are allowed to come from. This prevents a malicious site from using authentication credentials stored in your browser to send requests to your backend. Since CORS is usually something you worry about in the later stages of your app's development, we'll use a more production ready structure here. Instead of creating an app object at the global scope, we'll write app factory functions that create different apps depending on the configuration. This is one way to make an app work in both a production environment and locally for debugging. We will also be using [Router Middleware] to selectively apply middleware to only some routes. In particular, we'll leave the /health endpoint open to the public internet (you may or may not want to do this in production; this tutorial is not meant to be a security guide). Start by defining your data models and endpoint functions from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config ) Next define a configuration model for your application using Pydantic's Settings Management : from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config ) Now define a create_app() method that accepts a config and returns an App: from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config ) Finally, make a create_production_app() method that will load AppConfig from environment variables and pass that to create_app() : from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config ) For debugging or tests you might create a create_debug_app() method that passes in the cors_origin parameter to AppConfig or sets it as an environment variable before calling AppConfig() : from typing import Sequence from pydantic import BaseModel , BaseSettings from xpresso import App , Path , Router from xpresso.middleware import Middleware from xpresso.middleware.cors import CORSMiddleware from xpresso.routing.mount import Mount class AppHealth ( BaseModel ): okay : bool async def healthcheck () -> AppHealth : return AppHealth ( okay = True ) class Greeting ( BaseModel ): message : str async def greet_user () -> Greeting : return Greeting ( message = \"Hello!\" ) class AppConfig ( BaseSettings ): cors_origins : Sequence [ str ] def create_app ( config : AppConfig ) -> App : v1_router = Router ( routes = [ Path ( \"/landing\" , get = greet_user )], middleware = [ Middleware ( CORSMiddleware , allow_origins = config . cors_origins , allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) ], ) return App ( routes = [ Mount ( \"/v1\" , app = v1_router , ), Path ( \"/health\" , get = healthcheck , ), ], ) def create_production_app () -> App : config = AppConfig () # loaded from env variables return create_app ( config ) def create_debug_app () -> App : origins = ( \"http://localhost:8000\" , \"http://localhost:5000\" ) config = AppConfig ( cors_origins = origins ) return create_app ( config )","title":"Example: CORSMiddleware"}]}